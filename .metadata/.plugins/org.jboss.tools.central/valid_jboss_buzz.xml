<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Byteman 4.0.15 has been released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/pt5pDgRexD4/byteman-4015-has-been-released.html" /><author><name>Andrew Dinn</name></author><id>http://bytemanblog.blogspot.com/2021/05/byteman-4015-has-been-released.html</id><updated>2021-05-10T11:00:00Z</updated><content type="html">Byteman 4.0.15 is now available from the and from the . It is the latest update release for use on all JDK9+ runtimes up to and including JDK17. It is also recommended as the preferred release for use on JDK8- runtimes. Byteman 4.0.15 is a maintenance release which upgrades the versions of two components. More details are provided in the .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/pt5pDgRexD4" height="1" width="1" alt=""/&gt;</content><dc:creator>Andrew Dinn</dc:creator><feedburner:origLink>http://bytemanblog.blogspot.com/2021/05/byteman-4015-has-been-released.html</feedburner:origLink></entry><entry><title>Use knowledge graphs to discover open source package vulnerabilities</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/RmxxUhX1o2Q/" /><category term="Big Data" /><category term="Developer Tools" /><category term="Open source" /><category term="Security" /><category term="CodeReady Workspaces" /><category term="Dependency analytics" /><category term="knowledge graphs" /><category term="software vulnerabilities" /><author><name>DG Patel</name></author><id>https://developers.redhat.com/blog/?p=819317</id><updated>2021-05-10T07:00:39Z</updated><published>2021-05-10T07:00:39Z</published><content type="html">&lt;p&gt;Technology and infrastructure generate an enormous amount of data on a day-to-day basis. Building knowledge out of this data in various real-world domains can be a big challenge. This article describes how to derive concise and precise knowledge from data and use it to track vulnerabilities in the software stack. It presents challenges related to package security and vulnerability and how they can be addressed using a knowledge graph. After reading this article, you&amp;#8217;ll understand the concept of the knowledge graph and how you can apply it to your domain.&lt;/p&gt; &lt;h2&gt;Why open source packages introduce vulnerabilities&lt;/h2&gt; &lt;p&gt;Most large organizations employ open source libraries and components to build software used internally and externally. While &lt;a target="_blank" rel="nofollow" href="/topics/open-source/"&gt;open source&lt;/a&gt; helps solve many problems, developers need to understand how to &lt;a target="_blank" rel="nofollow" href="/topics/security"&gt;track security vulnerabilities&lt;/a&gt; in all the software they use. Security vulnerabilities can be brought into host software by the libraries and tools on which it depends. The problem grows as more and more dependencies are included.&lt;/p&gt; &lt;p&gt;Ensuring the most secure versions of software dependencies are used can be tedious and time consuming. Although open source package vulnerability databases are frequently updated, tracking those databases on a daily basis, or even per release, can be difficult during medium- and large-scale software development.&lt;/p&gt; &lt;p&gt;Questions you need to consider include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;What direct dependencies are vulnerable?&lt;/li&gt; &lt;li&gt;What is the recommended version to use for a dependency?&lt;/li&gt; &lt;li&gt;What exploits are a danger on a software stack based on current dependencies?&lt;/li&gt; &lt;li&gt;How do recent additions to the common vulnerabilities and exposures (CVE) list affect the application? What dependencies need to be modified to mitigate the risk?&lt;/li&gt; &lt;li&gt;How many projects in an organization are affected by newly reported vulnerabilities?&lt;/li&gt; &lt;li&gt;Are there any companion packages that can be used to mitigate the security risk?&lt;/li&gt; &lt;li&gt;What security risks are caused by transitive packages getting into software?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Knowledge graphs can help you find answers to these questions in a fast, automated manner.&lt;/p&gt; &lt;h2&gt;What are knowledge graphs?&lt;/h2&gt; &lt;p&gt;Real-world domains consist of many objects and the relationships between them. Because each object has relationships with others, which in turn have relationships with yet other objects, a complex mesh of interconnected objects (or &lt;em&gt;entities&lt;/em&gt;) emerges. In software design, we can represent these kinds of complex relationships between entities with a graph structure.&lt;/p&gt; &lt;p&gt;A &lt;em&gt;knowledge graph&lt;/em&gt; represents data about a knowledge domain as a graph structure that exposes the relationships between each pair of entities. A knowledge graph can organize huge, complex data in a meaningful way that makes the data easier to understand and be consumed. Human minds are built up of knowledge graphs, which allow us to relate concepts and extract required information in an efficient way (accurately and quickly).&lt;/p&gt; &lt;h3&gt;The advantages of a knowledge graph&lt;/h3&gt; &lt;p&gt;To understand the concept of a knowledge graph, let&amp;#8217;s consider a simple example. Say a company provides on-demand movies as a service. One of its business challenges is to provide more accurate recommendations based on the viewer&amp;#8217;s watch history. This learning has to be dynamic so the recommendations can change as viewer preferences shift over time.&lt;/p&gt; &lt;p&gt;The company could approach this challenge by arranging all of its data into a sequential data store and fetching recommendations, which are created by filtering the movies based on attributes from the viewer&amp;#8217;s watch history, such as genre, actors, production house, etc.&lt;/p&gt; &lt;p&gt;There are a few issues with this kind of flat data mining, though:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It is time-consuming, as we need to search the entire database for every recommendation.&lt;/li&gt; &lt;li&gt;Arranging results in order of most significant to least can be complex.&lt;/li&gt; &lt;li&gt;It does not scale well as the number of movies and viewers grows.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Alternatively, we can arrange this movie data in a graph structure, with &lt;em&gt;nodes&lt;/em&gt; representing entities like genre, lead actors, producer, release date, etc., and &lt;em&gt;edges&lt;/em&gt; representing the relationship. Figure 1 shows the lead actor and genre of three movies.&lt;/p&gt; &lt;div id="attachment_903087" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_60813516bd0ea.png"&gt;&lt;img aria-describedby="caption-attachment-903087" class="wp-image-903087 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_60813516bd0ea.png" alt="Movie data in knowledge graph format, showing the relationship between genres, films, and lead actor." width="640" height="430" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_60813516bd0ea.png 640w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_60813516bd0ea-300x202.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-903087" class="wp-caption-text"&gt;Figure 1: Movie data arranged in knowledge graph format.&lt;/p&gt;&lt;/div&gt; &lt;p id="ChyPHDo"&gt;Assume that a viewer has watched only one movie on the company&amp;#8217;s platform (for example, &lt;em&gt;Terminator 2: Judgement Day&lt;/em&gt;) and we have only the preceding information in our knowledge graph. The system can find the other movies with the same lead actor (in this case, &lt;em&gt;Predator&lt;/em&gt; and &lt;em&gt;Commando).&lt;/em&gt; To build in user preference, the system can also consider genre information. We see that &lt;em&gt;Terminator 2: Judgement Day&lt;/em&gt; and &lt;em&gt;Predator &lt;/em&gt;both fall under the Science Fiction genre. Given the limited data for this viewer, the recommendation system can easily rank the other movies they might enjoy—&lt;em&gt;Predator&lt;/em&gt;, followed by &lt;em&gt;Commando&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;This is a basic example to illustrate the concept. In fact, you will generally have many nodes and edges interconnecting them. The good part of this complex graph structure is that graph traversal does not grow exponentially with data size, as in the case of sequential data. At each transversal, we eliminate lots of invalid data from scanning, which provides efficient and quick information retrieval.&lt;/p&gt; &lt;p&gt;Knowledge graphs are used in many knowledge domains to serve real-world applications such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Search engines, to provide more appropriate content to the user.&lt;/li&gt; &lt;li&gt;Recommendation systems for e-commerce, entertainment, health, etc.&lt;/li&gt; &lt;li&gt;Targeted advertisement systems.&lt;/li&gt; &lt;li&gt;Offers and promotions for e-commerce.&lt;/li&gt; &lt;li&gt;User behavior analysis.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Advantages that knowledge graphs bring include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Semantic data representation.&lt;/li&gt; &lt;li&gt;Explicit knowledge representation.&lt;/li&gt; &lt;li&gt;Insights about data.&lt;/li&gt; &lt;li&gt;Continuously updated data.&lt;/li&gt; &lt;li&gt;Self-learning and adapting system.&lt;/li&gt; &lt;li&gt;Integration with machine learning and artificial intelligence.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Now let&amp;#8217;s take a look at how a knowledge graph can help us address vulnerabilities in software dependencies.&lt;/p&gt; &lt;h2&gt;Managing data when assessing package vulnerabilities&lt;/h2&gt; &lt;p&gt;A knowledge graph for package vulnerabilities requires a layout of the depth and breadth of data involved in this domain. If an application has just a couple of dependencies, most security questions can be answered by scanning source repositories and vulnerability databases. To find a dependency without known vulnerabilities, you need to match dependencies against non-vulnerable versions. However, the problem gets much more complicated when you have many dependencies, each in turn with its own dependencies (transitive dependencies). Today’s modern software solutions have many direct dependencies on other packages or modules produced by other developers, and these dependencies in turn are built on other packages.&lt;/p&gt; &lt;p&gt;Many packages have 100 or more versions, with many CVEs filed against those versions. Security and vulnerability data offered by private vendors add even more data requiring analysis. The possible combinations of these disparate sources result in a huge amount of data that needs to be scanned to identify the right combination of versions that have minimal or no vulnerabilities.&lt;/p&gt; &lt;p&gt;Additional burdens are added because the data stored is not static and changes over time. New CVEs may be discovered for older versions, there could be fixes for existing CVEs, etc. Thus, administrators need a considerable amount of time to keep their systems up to date with the latest and most accurate information.&lt;/p&gt; &lt;p&gt;Vulnerability assessment is too often ignored or looked down on as trivial work by software developers. The assessments require going through lots of data in order to find each vulnerability. When vulnerability assessment is not omitted altogether, it often is pushed off until the release date, where packages then get caught and blocked by security scanning software or the security team. Then the developers have to scramble to find the right dependencies and update their release.&lt;/p&gt; &lt;h2&gt;Moving from data to knowledge&lt;/h2&gt; &lt;p&gt;The proposed solution in this article is to organize the huge data about package versions and vulnerabilities from various sources into a knowledge base that can be queried as needed. The knowledge base can provide up-to-date and accurate information immediately. Other advantages include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A simpler, faster way for a developer to check for vulnerabilities.&lt;/li&gt; &lt;li&gt;More informed and accurate decisions about dependencies.&lt;/li&gt; &lt;li&gt;Security and vulnerability checks that occur much earlier in the development cycle of the software stack.&lt;/li&gt; &lt;li&gt;Continuous vulnerability scanning, such as by nightly jobs, or on every code commit to the repository.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Elements of a knowledge graph for software vulnerabilities&lt;/h2&gt; &lt;p&gt;A knowledge graph arranges the entities and relationships into a formal structure. The entities for package dependencies and vulnerabilities are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Source code repository (repo)&lt;/b&gt;: An entity that hosts one or more packages.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Package&lt;/b&gt;: A module or submodule that provides a reusable piece of software.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Version&lt;/b&gt;: A tag associated with a repo or package that identifies the unique instance or release of the source.&lt;/li&gt; &lt;li&gt;&lt;b&gt;CVE&lt;/b&gt;: A security-related flaw associated with versions of a repo or package.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The relationships between the entities are as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Has version&lt;/b&gt;: A one-to-many relationship between package and version.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Has CVE&lt;/b&gt;: A one-to-many relationship between version and CVE.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Has fixed version&lt;/strong&gt;: A one-to-one relationship between CVE and fixed version (if any).&lt;/li&gt; &lt;li&gt;&lt;b&gt;Has dependency&lt;/b&gt;: A one-to-many relationship between repo/package and version.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Has transitive dependency&lt;/b&gt;: A one-to-many relationship between repo and version.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Figure 2 shows the entities and their relationships.&lt;/p&gt; &lt;div id="attachment_902997" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_608115ab516b6.png"&gt;&lt;img aria-describedby="caption-attachment-902997" class="wp-image-902997 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_608115ab516b6.png" alt="A knowledge graph showing the entities for package dependencies and vulnerabilities" width="500" height="460" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_608115ab516b6.png 500w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/img_608115ab516b6-300x276.png 300w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-902997" class="wp-caption-text"&gt;Figure 2: The package dependencies and entities.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This exercise in data modeling has shown that vulnerability information for software packages can be articulated using a graph structure. Carrying out the analysis on real package data can form a knowledge graph you can use to protect your own software. Many graph databases, including open source ones, are available to represent your knowledge graph.&lt;/p&gt; &lt;p&gt;Accessing the &lt;em&gt;repo&lt;/em&gt; node, the system can find all the package versions (direct and transitive) that are vulnerable. It can build the list of CVEs associated with these package versions. Further for each CVE, the graph can also provide the fixed version of the package (if any) to address the vulnerability. These data and much can be retrieved from a simple knowledge graph of common vulnerability data.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The concept of a knowledge graph can be applied to any domain that contains many entities and relationships between them. You can curate your data into a compact knowledge graph that easily provides the right information, which is more accurate, quick, and efficient. Also, the knowledge graph&amp;#8217;s dynamic nature keeps it fresh and relevant. Choosing the appropriate database engine according to your business needs will make this solution more robust and allow it to scale over time.&lt;/p&gt; &lt;h2&gt;Related articles&lt;/h2&gt; &lt;p&gt;Here are the related articles on this approach:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/10/15/whats-new-in-red-hat-dependency-analytics/"&gt;What’s new in Red Hat Dependency Analytics&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/08/28/vulnerability-analysis-with-red-hat-codeready-dependency-analytics-and-snyk/"&gt;Vulnerability analysis with Red Hat CodeReady Dependency Analytics and Snyk Intel&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fuse-knowledge-graphs-to-discover-open-source-package-vulnerabilities%2F&amp;#38;linkname=Use%20knowledge%20graphs%20to%20discover%20open%20source%20package%20vulnerabilities" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fuse-knowledge-graphs-to-discover-open-source-package-vulnerabilities%2F&amp;#38;linkname=Use%20knowledge%20graphs%20to%20discover%20open%20source%20package%20vulnerabilities" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fuse-knowledge-graphs-to-discover-open-source-package-vulnerabilities%2F&amp;#38;linkname=Use%20knowledge%20graphs%20to%20discover%20open%20source%20package%20vulnerabilities" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fuse-knowledge-graphs-to-discover-open-source-package-vulnerabilities%2F&amp;#38;linkname=Use%20knowledge%20graphs%20to%20discover%20open%20source%20package%20vulnerabilities" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fuse-knowledge-graphs-to-discover-open-source-package-vulnerabilities%2F&amp;#38;linkname=Use%20knowledge%20graphs%20to%20discover%20open%20source%20package%20vulnerabilities" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fuse-knowledge-graphs-to-discover-open-source-package-vulnerabilities%2F&amp;#38;linkname=Use%20knowledge%20graphs%20to%20discover%20open%20source%20package%20vulnerabilities" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fuse-knowledge-graphs-to-discover-open-source-package-vulnerabilities%2F&amp;#38;linkname=Use%20knowledge%20graphs%20to%20discover%20open%20source%20package%20vulnerabilities" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fuse-knowledge-graphs-to-discover-open-source-package-vulnerabilities%2F&amp;#038;title=Use%20knowledge%20graphs%20to%20discover%20open%20source%20package%20vulnerabilities" data-a2a-url="https://developers.redhat.com/blog/2021/05/10/use-knowledge-graphs-to-discover-open-source-package-vulnerabilities/" data-a2a-title="Use knowledge graphs to discover open source package vulnerabilities"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/10/use-knowledge-graphs-to-discover-open-source-package-vulnerabilities/"&gt;Use knowledge graphs to discover open source package vulnerabilities&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/RmxxUhX1o2Q" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Technology and infrastructure generate an enormous amount of data on a day-to-day basis. Building knowledge out of this data in various real-world domains can be a big challenge. This article describes how to derive concise and precise knowledge from data and use it to track vulnerabilities in the software stack. It presents challenges related to [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/10/use-knowledge-graphs-to-discover-open-source-package-vulnerabilities/"&gt;Use knowledge graphs to discover open source package vulnerabilities&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/10/use-knowledge-graphs-to-discover-open-source-package-vulnerabilities/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">819317</post-id><dc:creator>DG Patel</dc:creator><dc:date>2021-05-10T07:00:39Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/10/use-knowledge-graphs-to-discover-open-source-package-vulnerabilities/</feedburner:origLink></entry><entry><title>Automating the testing process for SystemTap, Part 2: Test result analysis with Bunsen</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/hkJhJsP4AQo/" /><category term="CI/CD" /><category term="Linux" /><category term="Open source" /><category term="Performance" /><category term="Bunsen" /><category term="systemtap" /><category term="Test analysis" /><category term="test automation" /><author><name>Serhei Makarov</name></author><id>https://developers.redhat.com/blog/?p=844147</id><updated>2021-05-10T07:00:21Z</updated><published>2021-05-10T07:00:21Z</published><content type="html">&lt;p&gt;This is the second article of a two-part series in which I describe the automated testing infrastructure that I am developing for the SystemTap project. The first article, &amp;#8220;Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot,&amp;#8221; described my solution for managing test machines and for producing SystemTap test results. This follow-up article continues by describing Bunsen, the toolkit I developed for storing and analyzing test results.&lt;/p&gt; &lt;p&gt;Figure 1 summarizes the components of the testing infrastructure and how they interact.&lt;/p&gt; &lt;div id="attachment_843677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/12/bunsen-2020-12-workflow.png"&gt;&lt;img aria-describedby="caption-attachment-843677" class="wp-image-843677" src="https://developers.redhat.com/blog/wp-content/uploads/2020/12/bunsen-2020-12-workflow.png" alt="Components and their interactions in the SystemTap testing infrastructure. " width="640" height="686" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-843677" class="wp-caption-text"&gt;Figure 1: Components of the SystemTap testing infrastructure and their interactions.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Revisiting the seven steps for successful testing&lt;/h2&gt; &lt;p&gt;In Part 1, I listed seven steps for successfully testing a software project:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Step 1: Provisioning test machines and virtual machines (VMs).&lt;/li&gt; &lt;li&gt;Step 2: Installing the SystemTap project and running the test suite.&lt;/li&gt; &lt;li&gt;Step 3: Sending test results to a central location.&lt;/li&gt; &lt;li&gt;Step 4: Receiving and storing test results in a compact format.&lt;/li&gt; &lt;li&gt;Step 5: Querying the test results.&lt;/li&gt; &lt;li&gt;Step 6: Analyzing the test results.&lt;/li&gt; &lt;li&gt;Step 7: Reporting the analysis in a readable format.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The first three steps relate to testing the project and collecting test results. I discussed these steps in Part 1. The Bunsen toolkit implements the next four steps, which pertain to storing the collected test results and analyzing them. I will describe the implementation for each of these steps and finish by summarizing my key design ideas and outlining potential future improvements.&lt;/p&gt; &lt;h2&gt;Step 4: Receiving and storing test results in a compact format&lt;/h2&gt; &lt;p&gt;Once test results have been received by the test result server, they must be stored in a compact format for later analysis. For this purpose, I developed a test result storage and analysis toolkit called &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=summary"&gt;Bunsen&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Currently, Bunsen can parse, store, and analyze test result log files from projects whose test suites are based on the &lt;a target="_blank" rel="nofollow" href="https://www.gnu.org/software/dejagnu/"&gt;DejaGnu&lt;/a&gt; testing framework. Bunsen has been tested extensively with SystemTap test results, and work is also ongoing to adapt Bunsen for the requirements of the GDB (&lt;a target="_blank" rel="nofollow" href="https://www.gnu.org/software/gdb/"&gt;GNU Debugger&lt;/a&gt;) project.&lt;/p&gt; &lt;p&gt;Bunsen’s test result storage and indexing engine is based on the Git version control system. Bunsen stores a set of test results across several branches of a Git repository, according to the following scheme:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;First, Bunsen stores the original test result log files in the Git repository. The files are stored in a Git branch named according to the scheme &lt;code&gt;&lt;em&gt;projectname&lt;/em&gt;/testlogs-&lt;em&gt;year&lt;/em&gt;-&lt;em&gt;month&lt;/em&gt;&lt;/code&gt;. For example, log files from SystemTap testing obtained in August 2020 would be stored under &lt;code&gt;systemtap/testlogs-2020-08&lt;/code&gt;. Each revision in this branch stores a different set of test result log files. When a new revision is created for a new set of test results, log files for previously added test results are retained in the previous revision of the same branch, but are removed from the new revision. This minimizes the size of the Git working copy of each &lt;code&gt;testlogs&lt;/code&gt; branch. Because a set of test result log files may contain on the order of 50MB of plaintext data, a working copy that contained test result log files for many runs of the test suite could become extremely large. Storing one set of test results per revision makes it possible to check out working copies containing only one set of test results.&lt;/li&gt; &lt;li&gt;Second, Bunsen parses the test result log files and produces a representation of the test results in JSON format. The JSON representation contains the results for each test case, as well as a summary of the test machine configuration. The JSON representation also contains a reference to the commit ID of the &lt;code&gt;testlogs&lt;/code&gt; branch revision that stores the original test result log files. A simplified example follows showing how test results are converted to a JSON representation. Suppose the following results are contained in a &lt;code&gt;systemtap.log&lt;/code&gt; file: &lt;pre&gt; ... Running /opt/stap-checkout/testsuite/systemtap.base/cast-scope.exp ... doing compile Executing on host: g++ /opt/stap-checkout/testsuite/systemtap.base/cast-scope.cxx -g -isystem/opt/stap-chec\ kout/testsuite -isystem/opt/stap-checkout/stap_install/include -lm -o cast-scope-m32.exe (timeout = 300) spawn -ignore SIGHUP g++ /opt/stap-checkout/testsuite/systemtap.base/cast-scope.cxx -g -isystem/opt/stap-che\ ckout/testsuite -isystem/opt/stap-checkout/stap_install/include -lm -o cast-scope-m32.exe pid is 26539 -26539 output is PASS: cast-scope-m32 compile executing: stap /opt/stap-checkout/testsuite/systemtap.base/cast-scope.stp -c ./cast-scope-m32.exe PASS: cast-scope-m32 doing compile Executing on host: g++ /opt/stap-checkout/testsuite/systemtap.base/cast-scope.cxx -g -isystem/opt/stap-chec\ kout/testsuite -isystem/opt/stap-checkout/stap_install/include -lm -o cast-scope-m32.exe (timeout = 300) spawn -ignore SIGHUP g++ /opt/stap-checkout/testsuite/systemtap.base/cast-scope.cxx -g -isystem/opt/stap-che\ ckout/testsuite -isystem/opt/stap-checkout/stap_install/include -lm -o cast-scope-m32.exe pid is 26909 -26909 output is PASS: cast-scope-m32 compile executing: stap /opt/stap-checkout/testsuite/systemtap.base/cast-scope.stp -c ./cast-scope-m32.exe PASS: cast-scope-m32 doing compile Executing on host: g++ /opt/stap-checkout/testsuite/systemtap.base/cast-scope.cxx -g -isystem/opt/stap-chec\ kout/testsuite -isystem/opt/stap-checkout/stap_install/include -O -lm -o cast-scope-m32-O.exe (timeout = 300) spawn -ignore SIGHUP g++ /opt/stap-checkout/testsuite/systemtap.base/cast-scope.cxx -g -isystem/opt/stap-che\ ckout/testsuite -isystem/opt/stap-checkout/stap_install/include -O -lm -o cast-scope-m32-O.exe pid is 27279 -27279 output is PASS: cast-scope-m32-O compile executing: stap /opt/stap-checkout/testsuite/systemtap.base/cast-scope.stp -c ./cast-scope-m32-O.exe PASS: cast-scope-m32-O testcase /opt/stap-checkout/testsuite/systemtap.base/cast-scope.exp completed in 20 seconds Running /opt/stap-checkout/testsuite/systemtap.base/cast-user.exp ... doing compile Executing on host: gcc /opt/stap-checkout/testsuite/systemtap.base/cast-user.c -g -lm -o /opt/stap-check\ out/stap_build/testsuite/cast-user.exe (timeout = 300) spawn -ignore SIGHUP gcc /opt/stap-checkout/testsuite/systemtap.base/cast-user.c -g -lm -o /opt/stap-checkou\ t/stap_build/testsuite/cast-user.exe pid is 27649 -27649 output is PASS: cast-user compile executing: stap /opt/stap-checkout/testsuite/systemtap.base/cast-user.stp /opt/stap-checkout/stap_build/test\ suite/cast-user.exe -c /opt/stap-checkout/stap_build/testsuite/cast-user.exe FAIL: cast-user line 5: expected "" Got "WARNING: Potential type mismatch in reassignment: identifier 'cast_family' at /opt/stap-checkout/testsuite/systemta\ p.base/cast-user.stp:25:5" " source: cast_family = @cast(sa, "sockaddr", "&amp;#60;sys/socket.h&amp;#62;")-&amp;#62;sa_family" " ^" "Number of similar warning messages suppressed: 15." "Rerun with -v to see them." testcase /opt/stap-checkout/testsuite/systemtap.base/cast-user.exp completed in 6 seconds Running /opt/stap-checkout/testsuite/systemtap.base/cast.exp ... executing: stap /opt/stap-checkout/testsuite/systemtap.base/cast.stp FAIL: systemtap.base/cast.stp line 6: expected "" Got "WARNING: Potential type mismatch in reassignment: identifier 'cast_pid' at /opt/stap-checkout/testsuite/systemtap.b\ ase/cast.stp:14:5" " source: cast_pid = @cast(curr, "task_struct", "kernel&amp;#60;linux/sched.h&amp;#62;")-&amp;#62;tgid" " ^" "Number of similar warning messages suppressed: 4." "Rerun with -v to see them." testcase /opt/stap-checkout/testsuite/systemtap.base/cast.exp completed in 8 seconds ... &lt;/pre&gt; &lt;p&gt;Bunsen produces the following JSON representation of these test results:&lt;/p&gt; &lt;pre&gt; ... {"name": "systemtap.base/cast-scope.exp", "outcome": "PASS", "origin_sum": "systemtap.sum.autotest.2.6.32-754.33.1.el6.i686.2020-12-05T03:17-0500:383", "origin_log": "systemtap.log.autotest.2.6.32-754.33.1.el6.i686.2020-12-05T03:17-0500:3091-3116"}, {"name": "systemtap.base/cast-user.exp", "outcome": "FAIL", "subtest": "FAIL: cast-user\n", "origin_sum": "systemtap.sum.autotest.2.6.32-754.33.1.el6.i686.2020-12-05T03:17-0500:386"}, {"name": "systemtap.base/cast.exp", "outcome": "FAIL", "subtest": "FAIL: systemtap.base/cast.stp\n", "origin_sum": "systemtap.sum.autotest.2.6.32-754.33.1.el6.i686.2020-12-05T03:17-0500:388"}, ... &lt;/pre&gt; &lt;p&gt;The JSON representation is stored in a branch named according to the scheme &lt;code&gt;&lt;em&gt;projectname&lt;/em&gt;/testruns-&lt;em&gt;year&lt;/em&gt;-&lt;em&gt;month&lt;/em&gt;&lt;/code&gt;, for example &lt;code&gt;systemtap/testruns-2020-08&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Because the JSON representation is much more compact than the original test suite log files, the latest revision in the &lt;code&gt;testruns&lt;/code&gt; branch can retain all of the test suite runs stored in that branch. This makes it possible to check out a working copy summarizing all of the test results for one month.&lt;/li&gt; &lt;li&gt;Finally, Bunsen stores a summary of the JSON representation containing the test machine configuration, but not the detailed test results. This representation is appended to the file &lt;code&gt;&lt;em&gt;projectname&lt;/em&gt;-&lt;em&gt;year&lt;/em&gt;-&lt;em&gt;month&lt;/em&gt;.json&lt;/code&gt; in the branch &lt;code&gt;index&lt;/code&gt;. Therefore, to gain access to a summary of all of the test results in the Bunsen repository, it is sufficient to check out a working copy of this &lt;code&gt;index&lt;/code&gt; branch.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Figure 2 summarizes the layout of a Bunsen test result repository.&lt;/p&gt; &lt;div id="attachment_843687" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/12/bunsen-2020-12-layout.png"&gt;&lt;img aria-describedby="caption-attachment-843687" class="wp-image-843687" src="https://developers.redhat.com/blog/wp-content/uploads/2020/12/bunsen-2020-12-layout.png" alt="The branches, the relationships between branches, and the layout of a Bunsen test result repository." width="640" height="582" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-843687" class="wp-caption-text"&gt;Figure 2: Layout of a Bunsen test result repository.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The Git repository format provides significant space advantages for storing the test result log files, due to the large degree of similarity across different sets of test results. Across a large number of test suite runs, the same test case results and the same test case output tend to recur with only slight variations. Git’s internal representation &lt;a target="_blank" rel="nofollow" href="https://git-scm.com/book/en/v2/Git-Internals-Packfiles"&gt;can pack multiple test results into a compressed representation&lt;/a&gt; in which recurring test case results are de-duplicated.&lt;/p&gt; &lt;p&gt;For example, a collection of SystemTap test result logs collected from 1,562 runs of the test suite took up 103GB of disk space when stored uncompressed. A de-duplicated Git repository of the same test results produced by Bunsen took up only 2.7GB. This repository included both the original test result logs and the JSON representation of the test results.&lt;/p&gt; &lt;h2&gt;Step 5: Querying the test results&lt;/h2&gt; &lt;p&gt;In addition to the storage and indexing engine, Bunsen includes &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=tree;f=scripts-main"&gt;a collection of analysis scripts&lt;/a&gt; that can be used to extract information from a test result repository. Analysis scripts are Python programs that use Bunsen’s storage engine to access the repository.&lt;/p&gt; &lt;p&gt;Some of the analysis scripts included with Bunsen are intended for querying information about the content of specific test runs. The following example commands demonstrate how to locate and examine the results of a recent test run, and how to compare them with the results of prior runs.&lt;/p&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-main/list_runs.py"&gt;list_runs&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-main/list_commits.py"&gt;list_commits&lt;/a&gt; scripts list the test runs stored in the test results repository and display the Git commit ID of the test result log files. The &lt;code&gt;list_runs&lt;/code&gt; script simply lists all of the test runs; &lt;code&gt;list_commits&lt;/code&gt; takes the location of a checkout of the SystemTap Git repository and lists the test runs that tested each commit in the repository’s main branch:&lt;/p&gt; &lt;pre&gt;$ ./bunsen.py +list_commits source_repo=/opt/stap-checkout sort=recent restrict=3 commit_id: 1120422c2822be9e00d8d11cab3fb381d2ce0cce summary: PR27067 &amp;#60;&amp;#60;&amp;#60; corrected bug# for previous commit * 2020-12 5d53f76... pass_count=8767 fail_count=1381 arch=x86_64 osver=rhel-6 * 2020-12 c88267a... pass_count=8913 fail_count=980 arch=i686 osver=rhel-6 * 2020-12 299d9b4... pass_count=7034 fail_count=2153 arch=x86_64 osver=ubuntu-18-04 * 2020-12 53a18f0... pass_count=9187 fail_count=1748 arch=x86_64 osver=rhel-8 * 2020-12 7b37e97... pass_count=8752 fail_count=1398 arch=x86_64 osver=rhel-6 * 2020-12 8cd3b77... pass_count=8909 fail_count=1023 arch=i686 osver=rhel-6 * 2020-12 a450958... pass_count=10714 fail_count=2457 arch=x86_64 osver=rhel-7 * 2020-12 50dc14a... pass_count=10019 fail_count=3590 arch=x86_64 osver=fedora-31 * 2020-12 6011ae2... pass_count=9590 fail_count=2111 arch=i686 osver=fedora-30 * 2020-12 771bf86... pass_count=9976 fail_count=2617 arch=x86_64 osver=fedora-32 * 2020-12 1335891... pass_count=10013 fail_count=2824 arch=x86_64 osver=fedora-34 commit_id: 341bf33f14062269c52bcebaa309518d9972ca00 summary: staprun: handle more and fewer cpus better * 2020-12 368ee6f... pass_count=8781 fail_count=1372 arch=x86_64 osver=rhel-6 * 2020-12 239bbe9... pass_count=8904 fail_count=992 arch=i686 osver=rhel-6 * 2020-12 b138c0a... pass_count=6912 fail_count=2276 arch=x86_64 osver=ubuntu-18-04 * 2020-12 bf893d8... pass_count=9199 fail_count=1760 arch=x86_64 osver=rhel-8 * 2020-12 8be8643... pass_count=10741 fail_count=2450 arch=x86_64 osver=rhel-7 * 2020-12 94c84ab... pass_count=9996 fail_count=3662 arch=x86_64 osver=fedora-31 * 2020-12 a06bc5f... pass_count=10139 fail_count=2712 arch=x86_64 osver=fedora-34 * 2020-12 8d4ad0e... pass_count=10042 fail_count=2518 arch=x86_64 osver=fedora-32 * 2020-12 b6388de... pass_count=9591 fail_count=2146 arch=i686 osver=fedora-30 commit_id: a26bf7890196395d73ac193b23e271398731745d summary: relay transport: comment on STP_BULK message * 2020-12 1b91c6f... pass_count=8779 fail_count=1371 arch=x86_64 osver=rhel-6 * 2020-12 227ff2b... pass_count=8912 fail_count=983 arch=i686 osver=rhel-6 ... &lt;/pre&gt; &lt;p&gt;Given the Git commit ID for a test run, the &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-main/show_logs.py"&gt;show_logs&lt;/a&gt; script displays the contents of the test result log files for that test run. For example, the following &lt;code&gt;show_logs&lt;/code&gt; invocation examines the test results for the latest SystemTap commit on Fedora 32. Within the Bunsen repository, these test results have a Git commit ID of &lt;code&gt;771bf86&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ ./bunsen.py +show_logs testrun=771bf86 "key=systemtap.log*" | less ... Running /opt/stap-checkout/testsuite/systemtap.maps/map_hash.exp ... executing: stap /opt/stap-checkout/testsuite/systemtap.maps/map_hash_II.stp -DMAPHASHBIAS=-9999 FAIL: systemtap.maps/map_hash_II.stp -DMAPHASHBIAS=-9999 line 1: expected "array[2048]=0x1" Got "ERROR: Couldn't write to output 0 for cpu 1, exiting.: Bad file descriptor" executing: stap /opt/stap-checkout/testsuite/systemtap.maps/map_hash_II.stp -DMAPHASHBIAS=-9999 --runtime=dyninst FAIL: systemtap.maps/map_hash_II.stp -DMAPHASHBIAS=-9999 --runtime=dyninst line 1: expected "array[2048]=0x1" Got "array[2048]=1" "array[2047]=1" ... &lt;/pre&gt; &lt;p&gt;In addition to viewing test results directly, we typically want to compare them against test results from a known baseline version of the project. For the SystemTap project, a suitable baseline version would be a recent SystemTap release. To find the baseline, the &lt;code&gt;list_commits&lt;/code&gt; script can again be used to list test results for SystemTap commits around the time of release 4.4:&lt;/p&gt; &lt;pre&gt;$ pushd /opt/stap-checkout $ git log --oneline ... 931e0870a releng: update-po 1f608d213 PR26665: relayfs-on-procfs megapatch, rhel6 tweaks 988f439af (tag: release-4.4) pre-release: version timestamping, NEWS tweaks f3cc67f98 pre-release: regenerate example index 1a4c75501 pre-release: update-docs ... $ popd $ ./bunsen.py +list_commits source_repo=/notnfs/staplogs/upstream-systemtap sort=recent | less ... commit_id: 931e0870ae203ddc80d04c5c1425a6e3def49c38 summary: releng: update-po * 2020-11 6a3e8b1... pass_count=9391 fail_count=760 arch=x86_64 osver=rhel-6 * 2020-11 349cdc9... pass_count=9096 fail_count=800 arch=i686 osver=rhel-6 * 2020-11 136ebbb... pass_count=8385 fail_count=818 arch=x86_64 osver=ubuntu-18-04 * 2020-11 f1f93dc... pass_count=9764 fail_count=1226 arch=x86_64 osver=rhel-8 * 2020-11 2a70a1d... pass_count=10094 fail_count=1510 arch=x86_64 osver=fedora-33 * 2020-11 45aabfd... pass_count=11817 fail_count=1357 arch=x86_64 osver=rhel-7 * 2020-11 cfeee53... pass_count=9958 fail_count=1785 arch=i686 osver=fedora-30 * 2020-11 838831d... pass_count=11085 fail_count=2569 arch=x86_64 osver=fedora-31 * 2020-11 e07dd16... pass_count=10894 fail_count=1734 arch=x86_64 osver=fedora-32 commit_id: 988f439af39a359b4387963ca4633649866d8275 summary: pre-release: version timestamping, NEWS tweaks * 2020-11 2f928a5... pass_count=9877 fail_count=1270 arch=aarch64 osver=rhel-8 * 2020-11 815dfc0... pass_count=11831 fail_count=1345 arch=x86_64 osver=rhel-7 * 2020-11 f2ca771... pass_count=11086 fail_count=2562 arch=x86_64 osver=fedora-31 * 2020-11 5103bb5... pass_count=8400 fail_count=804 arch=x86_64 osver=ubuntu-18-04 * 2020-11 a5745c3... pass_count=9717 fail_count=1216 arch=x86_64 osver=rhel-8 * 2020-11 64de18e... pass_count=10094 fail_count=1464 arch=x86_64 osver=fedora-33 * 2020-11 b23e63d... pass_count=10895 fail_count=1733 arch=x86_64 osver=fedora-32 commit_id: 1a4c75501e873d1281d6c6c0fcf66c0f2fc1104e summary: pre-release: update-docs * 2020-11 78a1959... pass_count=8383 fail_count=819 arch=x86_64 osver=ubuntu-18-04 * 2020-11 7fd7908... pass_count=9753 fail_count=1214 arch=x86_64 osver=rhel-8 * 2020-11 935b961... pass_count=10092 fail_count=1509 arch=x86_64 osver=fedora-33 ... &lt;/pre&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-main/diff_runs.py"&gt;diff_runs&lt;/a&gt; script compares test results from two different test runs. For example, the following &lt;code&gt;diff_runs&lt;/code&gt; invocation compares the recent test results on Fedora 32 x86_64 with test results on the same system around the time of release 4.4:&lt;/p&gt; &lt;pre&gt;$ ./bunsen.py +diff_runs baseline=b23e63d latest=771bf86 | less ... * PASS=&amp;#62;FAIL systemtap.maps/map_hash.exp FAIL: systemtap.maps/map_hash_stat_II.stp * PASS=&amp;#62;FAIL systemtap.maps/map_hash.exp FAIL: systemtap.maps/map_hash_stat_SI.stp * PASS=&amp;#62;FAIL systemtap.maps/map_hash.exp FAIL: systemtap.maps/map_hash_stat_SSI.stp -DMAPHASHBIAS=2 * PASS=&amp;#62;FAIL systemtap.maps/map_wrap.exp FAIL: systemtap.maps/map_wrap2.stp ... &lt;/pre&gt; &lt;p&gt;Finally, the &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-main/diff_commits.py"&gt;diff_commits&lt;/a&gt; script compares all test results corresponding to two different revisions. Instead of presenting a separate comparison for each pair of test runs, &lt;code&gt;diff_commits&lt;/code&gt; attempts to select pairs of matching system configurations to compare.&lt;/p&gt; &lt;p&gt;The output of &lt;code&gt;diff_commits&lt;/code&gt; lists each changed test case exactly once, grouping test cases according to the set of comparisons in which they changed.&lt;/p&gt; &lt;p&gt;For example, the following &lt;code&gt;diff_commits&lt;/code&gt; invocation compares all test runs for the recent SystemTap commit 341bf33 with all of the test runs for the release 4.4 commit 988f439:&lt;/p&gt; &lt;pre&gt;$ ./bunsen.py +diff_commits source_repo=/notnfs/staplogs/upstream-systemtap baseline=988f439 latest=1120422 | less ... Regressions by version Found 9 regressions for: (arch=x86_64 osver=rhel-7) -&amp;#62; (arch=x86_64 osver=rhel-6) (arch=x86_64 osver=rhel-7) -&amp;#62; (arch=i686 osver=rhel-6) (arch=x86_64 osver=rhel-8) -&amp;#62; (arch=x86_64 osver=rhel-8) (arch=x86_64 osver=rhel-7) -&amp;#62; (arch=x86_64 osver=rhel-7) (arch=x86_64 osver=fedora-31) -&amp;#62; (arch=x86_64 osver=fedora-31) (arch=x86_64 osver=rhel-7) -&amp;#62; (arch=i686 osver=fedora-30) (arch=x86_64 osver=fedora-32) -&amp;#62; (arch=x86_64 osver=fedora-32) (arch=x86_64 osver=rhel-7) -&amp;#62; (arch=x86_64 osver=fedora-34) * PASS=&amp;#62;ERROR systemtap.apps/busybox.exp ERROR: tcl error sourcing /notnfs/smakarov/stap-checkout/testsuite/systemtap.apps/busybox.exp. * PASS=&amp;#62;FAIL systemtap.onthefly/kprobes_onthefly.exp FAIL: kprobes_onthefly - otf_start_disabled_iter_4 (stap) * PASS=&amp;#62;KFAIL systemtap.onthefly/tracepoint_onthefly.exp KFAIL: tracepoint_onthefly - otf_timer_10ms (stap) (PRMS: 17256) * KFAIL=&amp;#62;PASS systemtap.onthefly/tracepoint_onthefly.exp KFAIL: tracepoint_onthefly - otf_timer_10ms (invalid output) (PRMS: 17256) * PASS=&amp;#62;FAIL systemtap.printf/end1b.exp FAIL: systemtap.printf/end1b * PASS=&amp;#62;FAIL systemtap.printf/mixed_outb.exp FAIL: systemtap.printf/mixed_outb * PASS=&amp;#62;FAIL systemtap.printf/out1b.exp FAIL: systemtap.printf/out1b * PASS=&amp;#62;FAIL systemtap.printf/out2b.exp FAIL: systemtap.printf/out2b * PASS=&amp;#62;FAIL systemtap.printf/out3b.exp FAIL: systemtap.printf/out3b Found 3 regressions for: (arch=x86_64 osver=rhel-7) -&amp;#62; (arch=x86_64 osver=rhel-6) (arch=x86_64 osver=fedora-31) -&amp;#62; (arch=x86_64 osver=fedora-31) * FAIL=&amp;#62;PASS systemtap.apps/java.exp FAIL: multiparams (0) * FAIL=&amp;#62;PASS systemtap.apps/java.exp FAIL: multiparams 3.0 (0) * PASS=&amp;#62;FAIL systemtap.base/ret-uprobe-var.exp FAIL: ret-uprobe-var: TEST 1: @var in return probes should not be stale (4.1+) (kernel): stderr: string should be "", but got "ERROR: Couldn't write to output 0 for cpu 2, exiting.: Bad file descriptor ... &lt;/pre&gt; &lt;p&gt;Because the test results are stored in compressed format in a Git repository, there is a visible latency between invoking an analysis script and receiving the results. An invocation of &lt;code&gt;+list_runs&lt;/code&gt;, &lt;code&gt;+list_commits&lt;/code&gt;, or &lt;code&gt;+diff_runs&lt;/code&gt; takes on the order of 1 second to complete. An invocation of the &lt;code&gt;+diff_commits&lt;/code&gt; script must extract and compare multiple sets of test results, and takes on the order of 10 seconds to complete.&lt;/p&gt; &lt;h2&gt;Step 6: Analyzing the test results&lt;/h2&gt; &lt;p&gt;When we look at a recent set of test results, it is not always clear which test failures are new and which test failures occurred repeatedly over the history of the project. If a test failure has occurred repeatedly across many sets of test results, it is helpful to know when that the failure first appeared during the testing history of the project.&lt;/p&gt; &lt;p&gt;As an initial solution to filter out repeated test failures, I developed an analysis script named &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-main/find_regressions.py"&gt;find_regressions&lt;/a&gt;. This script traverses the Git history of the project in chronological order and checks the test results for each revision to identify new changes in test results.&lt;/p&gt; &lt;p&gt;If a change already occurred at least once within a configurable number of previous commits (for example, within the last 10 prior commits), it is considered to be an already occurring change. Otherwise, it is considered to be a newly occurring change.&lt;/p&gt; &lt;p&gt;This analysis filters out nondeterministic test cases whose results frequently change back and forth between &amp;#8220;pass&amp;#8221; and &amp;#8220;fail&amp;#8221; outcomes. The final output of &lt;code&gt;find_regressions&lt;/code&gt; lists the newly occurring changes associated with each commit, along with the number of times each change recurred after subsequent commits.&lt;/p&gt; &lt;p&gt;For example, &lt;a target="_blank" rel="nofollow" href="https://people.redhat.com/smakarov/2021-bunsen-blog-1/find-regressions-bpf.html"&gt;this HTML file&lt;/a&gt; produced by an invocation of &lt;code&gt;find_regressions&lt;/code&gt; summarizes newly occurring regressions in the &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=systemtap.git;a=blob;f=testsuite/systemtap.bpf/bpf.exp"&gt;bpf.exp&lt;/a&gt; test case for the 25 most recent revisions in the SystemTap project.&lt;/p&gt; &lt;p&gt;Of course, an ideal goal for test-result analysis would be to precisely identify the test result changes caused by each commit or by each change in the test environment. Because of the nature of the SystemTap test suite, precisely identifying a cause for each change in the test results is a difficult problem. Filtering out repeated failures can be thought of as a first approximation towards solving this problem.&lt;/p&gt; &lt;h2&gt;Step 7: Reporting the analysis in a readable format&lt;/h2&gt; &lt;p&gt;The examples in the previous section demonstrated how a Bunsen test results repository can be queried by logging into the test result server and invoking analysis scripts from the command line. However, this is not the most convenient way of examining test results. It would be preferable to access the test results remotely through a web interface.&lt;/p&gt; &lt;p&gt;The analysis scripts included with Bunsen include an option to generate test results in HTML format. In addition, the Bunsen toolkit includes a CGI script, &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=server/bunsen-cgi.py"&gt;bunsen-cgi.py&lt;/a&gt;, which accepts requests to run Bunsen analysis scripts and returns an HTML version of the analysis results.&lt;/p&gt; &lt;p&gt;For example, &lt;a target="_blank" rel="nofollow" href="https://people.redhat.com/smakarov/2021-bunsen-blog-1/list-commits.html"&gt;this HTML file&lt;/a&gt; was produced by an invocation of the &lt;code&gt;list_commits&lt;/code&gt; script and summarizes the test results for the 25 most recent revisions in the SystemTap project.&lt;/p&gt; &lt;p&gt;When developing the HTML option for Bunsen analysis output, I opted to keep the format simple for two reasons. First, I wanted to avoid the development and maintenance overheads associated with a more complex interactive web console such as Grafana. Second, I wanted the HTML files produced by Bunsen to be self-contained and viewable without having to make additional requests to the test results server, so that analysis output could be saved to disk, shared over email, and attached to bug reports.&lt;/p&gt; &lt;h2&gt;Conclusion to Part 2&lt;/h2&gt; &lt;p&gt;By carefully analyzing the requirements for testing the SystemTap project, I was able to eliminate a large portion of the manual effort required to produce and store test results. Along the way, I had to develop solutions for a number of difficulties.&lt;/p&gt; &lt;p&gt;First, I needed to test SystemTap across a large variety of Linux environments. To solve this problem, I used simple shell scripting and the &lt;a target="_blank" rel="nofollow" href="https://libvirt.org"&gt;libvirt&lt;/a&gt; framework’s extensive automation support to automate steps that previously had to be done manually to set up a SystemTap test machine.&lt;/p&gt; &lt;p&gt;Second, because of the large size of SystemTap’s test result log files, I needed a storage format with a significant compression factor. To solve this problem, I designed the Bunsen toolkit to take advantage of &lt;a target="_blank" rel="nofollow" href="https://git-scm.com/book/en/v2/Git-Internals-Packfiles"&gt;Git’s de-duplicated storage format&lt;/a&gt;. This format achieves a significant degree of compression at the cost of noticeable latency when querying the collected test results. In  the future, latency could be reduced by adding a caching layer between the compressed Git repository and the analysis scripts that access it.&lt;/p&gt; &lt;p&gt;Third, the large volume of test results and the large volume of nondeterministic test cases mean that it is a time-consuming manual task even to scrutinize the collected test results for new failures. Rather than rework the entire SystemTap test suite to eliminate nondeterministic and environment-dependent test cases, I decided to develop a solution based on improved analysis of test results. In the future, I hope to improve my analysis scripts and find more effective ways to filter out and report new changes in a project’s test results.&lt;/p&gt; &lt;p&gt;The difficult problem of test result analysis is not unique to the SystemTap project. Many other open source programs have test suites that are extremely large and include test cases with unpredictable behavior. Reworking the test suites to remove these test cases would tie up a large amount of scarce developer time. Therefore, it would be worthwhile to develop tools to make it easier to analyze collected test results across a variety of projects. The test result storage and analysis functionality in the Bunsen toolkit is a first step in that direction.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fautomating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%202%3A%20Test%20result%20analysis%20with%20Bunsen" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fautomating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%202%3A%20Test%20result%20analysis%20with%20Bunsen" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fautomating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%202%3A%20Test%20result%20analysis%20with%20Bunsen" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fautomating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%202%3A%20Test%20result%20analysis%20with%20Bunsen" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fautomating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%202%3A%20Test%20result%20analysis%20with%20Bunsen" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fautomating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%202%3A%20Test%20result%20analysis%20with%20Bunsen" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fautomating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%202%3A%20Test%20result%20analysis%20with%20Bunsen" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F10%2Fautomating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen%2F&amp;#038;title=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%202%3A%20Test%20result%20analysis%20with%20Bunsen" data-a2a-url="https://developers.redhat.com/blog/2021/05/10/automating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen/" data-a2a-title="Automating the testing process for SystemTap, Part 2: Test result analysis with Bunsen"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/10/automating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen/"&gt;Automating the testing process for SystemTap, Part 2: Test result analysis with Bunsen&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/hkJhJsP4AQo" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This is the second article of a two-part series in which I describe the automated testing infrastructure that I am developing for the SystemTap project. The first article, &amp;#8220;Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot,&amp;#8221; described my solution for managing test machines and for producing SystemTap test results. [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/10/automating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen/"&gt;Automating the testing process for SystemTap, Part 2: Test result analysis with Bunsen&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/10/automating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">844147</post-id><dc:creator>Serhei Makarov</dc:creator><dc:date>2021-05-10T07:00:21Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/10/automating-the-testing-process-for-systemtap-part-2-test-result-analysis-with-bunsen/</feedburner:origLink></entry><entry><title type="html">Kafka Monitoring Dashboards with Business Central</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/K6YHkmYZsOo/kafka-monitoring-dashboards-from-business-central.html" /><author><name>William Siqueira</name></author><id>https://blog.kie.org/2021/05/kafka-monitoring-dashboards-from-business-central.html</id><updated>2021-05-07T18:41:36Z</updated><content type="html">Kafka is one of the major platforms for async communication in cloud computing and jBPM has a nice with it, making it part of a business process. In real-world projects, monitoring the Kafka queues used by jBPM can help you to identify process bottlenecks. Previously we talked about in Business Central via DashBuilder, and today we will show how to monitor Kafka queues from jBPM using a Kafka Data Set which is included by Business Central 7.52.0 and onwards. KAFKA DATA SETS The first step to build a dashboard is having data sets. To retrieve information from Kafka, Business Central needs to invoke Kafka “mbeans” and all the metrics are identified after the MBeans names. (for more information, check the about how to monitor Kafka installations) Having this said, bear in mind that the metrics are a snapshot of the Kafka status, because it does not accumulate value. For this purpose, users must set up an agent in Kafka and store the metrics in a system like Prometheus for cumulative and historical values. Business Central supports 3 types of Kafka data sets: * BROKER: When using Broker you will be monitoring Kafka server metrics, general metrics; * CONSUMER: To monitor consumers and messages handled by a consumer; * PRODUCER: To monitor producers and messages created by a producer. The common parameters for all types are: * Name: Give the data set a name; * Host: The host where Kafka component (BROKER,CONSUMER or PRODUCER) is running; * Port: The JMX port. When making Kafka available for monitoring you must set a JMX port; * Target: Select the target installation type: BROKER, CONSUMER, PRODUCER; * Filter: Any text used to filter the result, this way we can create data sets focused on a specific set of results. It is a “LIKE” operation, which means that it only shows results that contain the text in the filter The properties above are all you need to create BROKER metrics. When you select CONSUMER or PRODUCER then there are other possible parameters: * ClientID: This is a mandatory field for CONSUMER and PRODUCER, it identifies the client ID; * NodeID: The node id is an optional parameter to identify a node from which we want metrics from; * TopicID: The topic id is an optional parameter used to identify a topic from which we want metrics from. To create a Kafka Data Set, log in Business Central, go to Admin -&gt; Data Sets, click on “New Data Set” and select Kafka from the list: Now, you can fill the required fields and test the data set. After a successful test, you can go back to the setup screen to add a filter if necessary. KAFKA MONITORING DASHBOARD Now that we know about Kafka data sets let’s create a simple Dashboard. First, make sure you downloaded Kafka locally. Using Docker is possible but you must make sure that JMX ports are exposed. 1. Download Kafka 2. Start Zookeeper in a console ./bin/zookeeper-server-start.sh config/zookeeper.properties 3. In a new console start Kafka (Broker) — before export JMX_PORT=9999 export JMX_PORT=9999 ./bin/kafka-server-start.sh config/server.properties 4. Create the topic using some console window ./bin/kafka-topics.sh — create — topic example-topic — bootstrap-server localhost:9092 — replication-factor 1 — partitions 1 5. In a new console start a Consumer — export JMX_PORT=9998 export JMX_PORT=9998 ./bin/kafka-console-consumer.sh — group dashbuilder_test — topic example-topic — bootstrap-server localhost:9092 6. In a new console start the Producer export JMX_PORT=9997 ./bin/kafka-console-producer.sh — topic example-topic — broker-list localhost:9092 In the producer window, you can type the text that will be received by the consumer. We are done on the Kafka side, now let’s create the required data sets in Business Central. Let’s create three of them, one for each type using the following parameters. Host: localhost Port: 9999 for broker — 9998 for consumer and 9997 for producer Client ID: console-producer for producer or consumer-dashbuilder_test-1 for consumer Topic: example-topic BROKER: BROKER OUTPUT: CONSUMER: CONSUMER OUTPUT PRODUCER: PRODUCER OUTPUT: With these 3 data sets, we can now monitor the topic “example-topic” and query everything about the broker. In Business Central you can now create dashboards using the data sets we created: * Go to Design -&gt; Pages and create a new Page * Drag the Table Reporting component to the page and select any of the Kafka data sets Since each metric is a data set row, to show a specific attribute we can also filter the data set when building the data set, here’s an example to show specifically the number of records for the producer: Users can decide to create specific data sets for the wanted attributes using the filter field or create a data set with all attributes and filters when creating the dashboard. If you followed the steps above to set up Kafka you can import the in and it should work. CONCLUSION In this post, we show how to create Kafka data sets and Dashboards in Business Central and how to import it in Dashbuilder Runtime. With this new feature, we can monitor all the parts of a business process when it uses Kafka to identify bottlenecks or simply monitor any Kafka installation from Business Central. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/K6YHkmYZsOo" height="1" width="1" alt=""/&gt;</content><dc:creator>William Siqueira</dc:creator><feedburner:origLink>https://blog.kie.org/2021/05/kafka-monitoring-dashboards-from-business-central.html</feedburner:origLink></entry><entry><title type="html">Infinispan 12.1.2.Final</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/kAc0iUombkc/infinispan-12-1-2-final" /><author><name>Katia Aresti</name></author><id>https://infinispan.org/blog/2021/05/07/infinispan-12-1-2-final</id><updated>2021-05-07T12:00:00Z</updated><content type="html">Dear Infinispan community, It’s been a month since our first 12.1.0.Final release and we already released two additional minors with some bug fixes and upgrades. The latest version is 12.1.2.Final. Highlights of Infinispan 12.1.1 and 12.1.2 include: * Grafana Dashboards for the Operator . * Performance regression fix . * Index and Query statistics improved in the Infinispan Web Console . * Several component upgrades * Documentation enchancements You can find release notes for both versions at: and&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/kAc0iUombkc" height="1" width="1" alt=""/&gt;</content><dc:creator>Katia Aresti</dc:creator><feedburner:origLink>https://infinispan.org/blog/2021/05/07/infinispan-12-1-2-final</feedburner:origLink></entry><entry><title>Report from the virtual ISO C++ meetings in 2020 (core language)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/K9K7zXVNh9U/" /><category term="C" /><category term="Linux" /><category term="Open source" /><category term="Programming Languages" /><category term="C++ standard" /><category term="gcc" /><category term="ISO C++" /><author><name>Jason Merrill</name></author><id>https://developers.redhat.com/blog/?p=849117</id><updated>2021-05-07T07:00:48Z</updated><published>2021-05-07T07:00:48Z</published><content type="html">&lt;p&gt;C++ standardization was dramatically different in 2020 from earlier years. The business of the International Organization for Standardization (ISO) committee all took place virtually, much like everything else during this pandemic. This article summarizes the &lt;a target="_blank" rel="nofollow" href="/topics/c"&gt;C++&lt;/a&gt; standardization proposals before the Core and Evolution Working Groups last year.&lt;/p&gt; &lt;h2&gt;Core language&lt;/h2&gt; &lt;p&gt;The C++ Core Working Group (CWG) had already been holding monthly Zoom teleconferences between meetings; this was how I encountered Zoom in the before times. So the transition for us was fairly smooth.&lt;/p&gt; &lt;p&gt;We did end up moving a few papers at a virtual full committee plenary on one of the days of the canceled November meeting.&lt;/p&gt; &lt;h3&gt;Literal suffix for (signed) size_t&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p0330"&gt;P0330&lt;/a&gt;) was ready after the Belfast meeting in November 2019, but because it was intended as a C++23 feature, we didn&amp;#8217;t want to bring it up for a vote until after we finished C++20. This proposal makes it easier to write a constant of &lt;code&gt;size_t&lt;/code&gt; or &lt;code&gt;ptrdiff_t&lt;/code&gt; type. This practice is useful, for instance, to match the return type of a &lt;code&gt;size()&lt;/code&gt; function:&lt;/p&gt; &lt;pre&gt;auto m = std::max (0, v.size()); // error, deduction mismatch int vs. size_t auto m = std::max (0uz, v.size()); // OK, both arguments are size_t&lt;/pre&gt; &lt;p&gt;Earlier versions of this proposal used &lt;code&gt;t&lt;/code&gt; for &lt;code&gt;ptrdiff_t&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt; for &lt;code&gt;size_t&lt;/code&gt;, like the &lt;code&gt;printf&lt;/code&gt; conversion specifiers, but the final version uses &lt;code&gt;uz&lt;/code&gt; for &lt;code&gt;size_t&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt; for the corresponding signed type (usually the same as &lt;code&gt;ptrdiff_t&lt;/code&gt;).&lt;/p&gt; &lt;h3&gt;Numeric and universal character escapes in character and string literals&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2029"&gt;P2029&lt;/a&gt;) clarifies the handling of hex and octal character escapes to standardize the GNU Compiler Collection (GCC) behavior rather than the (Microsoft Visual C++) MSVC behavior: Namely, that a single escape code can correspond to a single UTF-8 code unit, not necessarily an entire character.&lt;/p&gt; &lt;pre&gt;constexpr const char8_t c[] = u8"\xc3\x80"; // UTF-8 encoding of U+00C0 {LATIN CAPITAL LETTER A WITH GRAVE}&lt;/pre&gt; &lt;h3&gt;Declarations and where to find them&lt;/h3&gt; &lt;p&gt;During the week of the planned June meeting, CWG decided to meet for the full week, two hours a day, to continue reviewing a paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1787"&gt;P1787&lt;/a&gt;) we had started to look at in Prague: An ambitious proposal to overhaul the wording for declaration scope and name lookup completely, and thereby fix more than 60 open issues. One week stretched into three before we got through the whole paper.&lt;/p&gt; &lt;p&gt;This paper&amp;#8217;s changes should not affect a significant amount of code; many changes are clarifications that bring the wording in line with existing practice. Some are clarifications of corner cases that most code doesn&amp;#8217;t depend on, such as ambiguous lookup within a &lt;em&gt;conversion-type-id&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;A few changes allow code that was previously ill-formed:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;em&gt;conversion-type-id&lt;/em&gt; is added to the list of type-only contexts from &lt;a target="_blank" rel="nofollow" href="http://wg21.link/p0634"&gt;P0634&lt;/a&gt;: &lt;pre&gt;template &amp;#60;class T&amp;#62; struct A { operator T::type(); }; // OK&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;&lt;code&gt;::template&lt;/code&gt; is also not required in type-only contexts: &lt;pre&gt;template &amp;#60;class T&amp;#62; auto f(T t) { return static_cast&amp;#60;T::X&amp;#60;int&amp;#62;&amp;#62;(t); } // OK&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Default template arguments are now complete-class contexts, like default function arguments: &lt;pre&gt;template &amp;#60;class T&amp;#62; struct A { template &amp;#60;int I = sizeof(t)&amp;#62; void g() { } // OK T t; };&lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;One change might break a small amount of existing code: Because the lookup for a name after a dot (.) or arrow operator (-&amp;#62;) now happens first in the scope of the object, &lt;code&gt;.template&lt;/code&gt; is required in &lt;code&gt;&lt;em&gt;dependent&lt;/em&gt;.template X&amp;#60;...&amp;#62;&lt;/code&gt; even if a definition of X would be found by  an unqualified lookup:&lt;/p&gt; &lt;pre&gt;template &amp;#60;int&amp;#62; struct X { void f(); }; template &amp;#60;class T&amp;#62; void g(T t) { t.X&amp;#60;2&amp;#62;::f(); } // error, needs .template&lt;/pre&gt; &lt;h3&gt;Generalized wording for partial specializations&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2096"&gt;P2096&lt;/a&gt;) just cleaned up places in the standard that still referred to partial specializations only for classes, so that these places cover variable partial specializations, as well.&lt;/p&gt; &lt;h3&gt;Down with ()!&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1102"&gt;P1102&lt;/a&gt;) has completed its Core review and should be ready for a vote at the next virtual plenary. The paper proposes a change to lambda syntax to avoid requiring () in a mutable lambda:&lt;/p&gt; &lt;pre&gt;[x = 42] () mutable { ++x; }; // () are uselessly required in C++20&lt;/pre&gt; &lt;h2&gt;Language evolution&lt;/h2&gt; &lt;p&gt;The C++ Evolution Working Group (EWG) has been meeting regularly to discuss future directions, but as a matter of policy, has not been voting to forward papers to the CWG until a face-to-face meeting takes place.  Recently, they decided on electronic voting, and the following papers were up for EWG voting through February.&lt;/p&gt; &lt;h3&gt;Narrowing contextual conversions to bool&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="http://wg21.link/cwg2039"&gt;CWG2039&lt;/a&gt; changed the condition of a &lt;code&gt;static_assert&lt;/code&gt; to reject narrowing conversions to &lt;code&gt;bool&lt;/code&gt;, for instance, from integers larger than 1. This seems to have been unintended, and most compilers haven&amp;#8217;t implemented it yet. So this paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1401"&gt;P1401&lt;/a&gt;) changes the feature back and makes the same change to the condition of &lt;code&gt;if constexpr&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;static_assert (2, "two"); // OK again&lt;/pre&gt; &lt;h3&gt;Make declaration order layout mandated&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1847"&gt;P1847&lt;/a&gt;) argues that because no compiler actually reorders data members with different access, we should drop that permission.&lt;/p&gt; &lt;h3&gt;if consteval&lt;/h3&gt; &lt;p&gt;This proposed mechanism (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1938"&gt;P1938&lt;/a&gt;) is much like &lt;code&gt;if (std::is_constant_evaluated())&lt;/code&gt;, except that the first block of the &lt;code&gt;if&lt;/code&gt; is an immediate function context, allowing calls to &lt;code&gt;consteval&lt;/code&gt; functions with arguments that depend on the parameters of the current (&lt;code&gt;constexpr&lt;/code&gt;) function.&lt;/p&gt; &lt;h3&gt;C++ identifier syntax using Unicode standard annex 31&lt;/h3&gt; &lt;p&gt;C++ has periodically needed to change its list of Unicode characters that are allowed in identifiers; this paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p1949"&gt;P1949&lt;/a&gt;) proposes adopting the set specified by the actual Unicode standard, which has stabilized since C++11.&lt;/p&gt; &lt;h3&gt;Freestanding optional operator new&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2013"&gt;P2013&lt;/a&gt;) proposes that a freestanding implementation need not provide a definition of the replaceable &lt;code&gt;new&lt;/code&gt; operator.&lt;/p&gt; &lt;h3&gt;Allow duplicate attributes&lt;/h3&gt; &lt;p&gt;C++11 attributes disallowed the repetition of the same attribute within a single attribute list, like &lt;code&gt;[[nodiscard, nodiscard]]&lt;/code&gt;. C recently removed this restriction, and this paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2156"&gt;P2156&lt;/a&gt;) proposes to do the same for C++.&lt;/p&gt; &lt;h3&gt;Attributes on lambda-expressions&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2173"&gt;P2173&lt;/a&gt;) proposes allowing attributes to appear in a lambda after the lambda-introducer, such as:&lt;/p&gt; &lt;pre&gt;[] [[nodiscard]] (int x) { return x; }&lt;/pre&gt; &lt;h3&gt;Removing garbage collection support&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2186"&gt;P2186&lt;/a&gt;) points out that there are no implementations of the C++11 &amp;#8220;minimal support for garbage collection,&amp;#8221; and that several C++ implementations of actual garbage collection don&amp;#8217;t interact with the C++11 feature, and so proposes removing it.&lt;/p&gt; &lt;h3&gt;Mixed string literal concatenation&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2201"&gt;P2201&lt;/a&gt;) proposes changing the concatenation of string literals with different encoding prefixes from conditionally supported to ill-formed.&lt;/p&gt; &lt;h3&gt;Trimming whitespaces before line splicing&lt;/h3&gt; &lt;p&gt;This paper (&lt;a target="_blank" rel="nofollow" href="http://wg21.link/p2223"&gt;P2223&lt;/a&gt;) proposes ignoring any whitespace after a backslash (\) at the end of a line, except in a raw string.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The various working groups continued to meet virtually through the beginning of the year, and had another virtual plenary the week of the originally planned February meeting.  Currently the tentative plan is to continue meeting virtually through the end of 2021 and meet in person again in February 2022.&lt;/p&gt; &lt;p&gt;For more information on C and C++, please visit &lt;a target="_blank" rel="nofollow" href="/topics/c"&gt;Red Hat Developer&amp;#8217;s topic page&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#38;linkname=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Freport-from-the-virtual-iso-c-meetings-in-2020-core-language%2F&amp;#038;title=Report%20from%20the%20virtual%20ISO%20C%2B%2B%20meetings%20in%202020%20%28core%20language%29" data-a2a-url="https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/" data-a2a-title="Report from the virtual ISO C++ meetings in 2020 (core language)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/"&gt;Report from the virtual ISO C++ meetings in 2020 (core language)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/K9K7zXVNh9U" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;C++ standardization was dramatically different in 2020 from earlier years. The business of the International Organization for Standardization (ISO) committee all took place virtually, much like everything else during this pandemic. This article summarizes the C++ standardization proposals before the Core and Evolution Working Groups last year. Core language The C++ Core Working Group (CWG) [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/"&gt;Report from the virtual ISO C++ meetings in 2020 (core language)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">849117</post-id><dc:creator>Jason Merrill</dc:creator><dc:date>2021-05-07T07:00:48Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/07/report-from-the-virtual-iso-c-meetings-in-2020-core-language/</feedburner:origLink></entry><entry><title>Use multiple compilers to build better projects</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/xXslsKHu7G0/" /><category term="C" /><category term="clang/LLVM" /><category term="Linux" /><category term="Performance" /><category term="C/C++ compilers" /><category term="CI pipelines" /><category term="debugging" /><category term="gcc" /><author><name>Timm Baeder</name></author><id>https://developers.redhat.com/blog/?p=896297</id><updated>2021-05-07T07:00:28Z</updated><published>2021-05-07T07:00:28Z</published><content type="html">&lt;p&gt;For a multitude of reasons, developers usually compile the project they are working on with only one compiler. On &lt;a target="_blank" rel="nofollow" href="/products/rhel/overview"&gt;Red Hat Enterprise Linux 8&lt;/a&gt;, the system compiler for &lt;a target="_blank" rel="nofollow" href="/topics/c"&gt;C and C++&lt;/a&gt; is GNU Compiler Collection (GCC) 8, and newer versions are available through the GCC toolset.&lt;/p&gt; &lt;p&gt;However, there are several reasons why you might also build your project with &lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/"&gt;Clang&lt;/a&gt;. Red Hat Enterprise Linux 8 offers the &lt;a target="_blank" rel="nofollow" href="https://llvm.org/"&gt;LLVM&lt;/a&gt; toolset, which contains &lt;a target="_blank" rel="nofollow" href="/blog/category/clang-llvm/"&gt;Clang&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In this article, we&amp;#8217;ll take a look at why one might use more than one compiler. We&amp;#8217;ll focus on a system where GCC is currently the default compiler and consider Clang as the main alternative.&lt;/p&gt; &lt;h2&gt;Detecting compiler-specific behavior&lt;/h2&gt; &lt;p&gt;When you try to compile a project with a compiler not usually used by the project, one of the most frequent problems is the project&amp;#8217;s assumptions about the compiler in use. These assumptions can appear in many places within a project, from command-line options to supported features to compiler extensions.&lt;/p&gt; &lt;p&gt;Generally, all of those compiler-specific features are to be avoided, unless the project explicitly supports only compilers that offer nonstandard features. If you depend on a particular compiler or nonstandard features, that dependency should be documented in the project&amp;#8217;s build documentation and ideally enforced by the build system.&lt;/p&gt; &lt;p&gt;To ensure that a project keeps building with other compilers, it is useful to regularly build it with a new compiler. Such a build can also detect implementation-defined behavior, undefined behavior, and (in rare cases) compiler bugs.&lt;/p&gt; &lt;p&gt;Other potential problems include differences in supported &lt;code&gt;__attribute__((foo))&lt;/code&gt; directives (or &lt;code&gt;[[attribute-name]]&lt;/code&gt; for C++), differences in supported language standards, and the use of unimplemented compiler built-ins.&lt;/p&gt; &lt;h2&gt;Getting different error messages from multiple compilers&lt;/h2&gt; &lt;p&gt;One of the biggest benefits of using a modern compiler is the warnings and error messages it generates, based on the command-line options the developers pass. Fixing these warnings can result in better code quality, increased portability, and fewer bugs.&lt;/p&gt; &lt;p&gt;One common problem is that not all compilers accept the same command-line arguments, so projects have to check for them at configure time. Depending on the needs of the project, most end up maintaining a list of compiler options for each compiler they build with.&lt;/p&gt; &lt;p&gt;Because figuring out whether a compiler supports a command-line option is so common, the usual build systems have built-in ways of performing these checks.&lt;/p&gt; &lt;p&gt;CMake uses the &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://cmake.org/cmake/help/v3.14/module/CheckCCompilerFlag.html"&gt;check_c_compiler_flag()&lt;/a&gt;&lt;/code&gt; or &lt;code&gt;&lt;a target="_blank" rel="nofollow" href="https://cmake.org/cmake/help/latest/module/CheckCXXCompilerFlag.html"&gt;check_cxx_compiler_flag()&lt;/a&gt;&lt;/code&gt; functions:&lt;/p&gt; &lt;pre&gt;include(CheckCCompilerFlag) check_c_compiler_flag("-Werror=header-guard", CC_SUPPORTS_HEADER_GUARD) check_c_compiler_flag("-Werror=logical-op", CC_SUPPORTS_LOGICAL_OP) &lt;/pre&gt; &lt;p&gt;Meson uses the &lt;code&gt;get_supported_arguments()&lt;/code&gt; function of the compiler object:&lt;/p&gt; &lt;pre&gt;test_cflags = [    '-Werror=header-guard',    '-Werror=logical-op' ] cc = meson.get_compiler('c') supported_flags = cc.get_supported_arguments(test_cflags) &lt;/pre&gt; &lt;p&gt;There are many more build systems, of course, but they all provide a more-or-less elegant way of dealing with this issue.&lt;/p&gt; &lt;p&gt;So, having configured our build with checks for compiler options, we can have a successful build with both Clang and GCC, or potentially any other compiler.&lt;/p&gt; &lt;p&gt;The following code shows an error when built with GCC, using the &lt;code&gt;-Wlogical-op&lt;/code&gt; command-line option. Clang does not support that option and remains silent about the suspicious use of logical operators:&lt;/p&gt; &lt;pre&gt;int main(int argc, char **argv) { if (argc &amp;#62; 0 &amp;#38;&amp;#38; argc &amp;#62; 0) {      return 1;    }    return 0; } &lt;/pre&gt; &lt;p&gt;GCC 10&amp;#8217;s output with &lt;code&gt;-Wlogical-op&lt;/code&gt; looks like this:&lt;/p&gt; &lt;pre&gt;test.c: In function ‘main’: test.c:2:16: warning: logical ‘and’ of equal expressions [-Wlogical-op] 2 | if (argc &amp;#62; 0 &amp;#38;&amp;#38; argc &amp;#62; 0) { | ~~~~~~~~~^~~~~~~~~~~ &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: See this code on &lt;a target="_blank" rel="nofollow" href="https://godbolt.org/z/Mz191P4oc"&gt;godbolt.org&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As already mentioned, Clang ignores this (potential) problem. But if we include the following header file in our previous test, GCC will remain silent about the typo in the header guard, while Clang will helpfully point out the mistake. Header guards like this are still relatively common in both C and C++ code, and the problem is usually hard to find:&lt;/p&gt; &lt;pre&gt;#ifndef __TEST_HEADER_H__ #define __TEST_HEADRE_H__ /* ... Code ...*/ #endif &lt;/pre&gt; &lt;p&gt;Clang with the &lt;code&gt;-Werror=header-guard&lt;/code&gt; option tells us about the broken header guard:&lt;/p&gt; &lt;pre&gt;In file included from test.c:3: ./test.h:1:9: error: '__TEST_HEADER_H__' is used as a header guard here, followed by #define of a different macro [-Werror,-Wheader-guard] #ifndef __TEST_HEADER_H__         ^~~~~~~~~~~~~~~~~ ./test.h:2:9: note: '__TEST_HEADRE_H__' is defined here; did you mean '__TEST_HEADER_H__'? #define __TEST_HEADRE_H__         ^~~~~~~~~~~~~~~~~         __TEST_HEADER_H__ &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: See this code on &lt;a target="_blank" rel="nofollow" href="https://godbolt.org/z/87668f1sE"&gt;godbolt.org&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;GCC is unable to detect this problem. The examples of different behavior I&amp;#8217;ve shown in this section are just two of many examples one could find.&lt;/p&gt; &lt;p&gt;In practice, if the compilers emit only warnings and not errors, their usefulness depends on a developer actually looking at the compiler output. Passing &lt;code&gt;-Werror&lt;/code&gt; to the compiler during development is also useful because it makes the compiler treat all warnings as errors.&lt;/p&gt; &lt;h2&gt;Static analysis&lt;/h2&gt; &lt;p&gt;One particularly well-known part of Clang is the &lt;a target="_blank" rel="nofollow" href="https://clang-analyzer.llvm.org/"&gt;static analyzer&lt;/a&gt;. Static analysis can be used to analyze certain aspects of a program &amp;#8220;statically,&amp;#8221; meaning, before runtime. This allows for more thorough checking because the time taken by the analyzer is not as important as the time taken by the compiler.&lt;/p&gt; &lt;p&gt;Because it does not need manual intervention, static analysis is particularly useful in &lt;a target="_blank" rel="nofollow" href="/topics/ci-cd"&gt;continuous integration (CI)&lt;/a&gt;, where we can use it for every push to a repository. However, it is usually hard to keep code 100% clean of reports from the static analyzer. This is partly due to how thorough static analyzers are: They find many problems that compilers don&amp;#8217;t find, but some of these are false positives, caused by implicit invariants the analyzer doesn&amp;#8217;t know about. Encoding these assumptions in the form of assertions usually improves code clarity and also makes the analyzer happy.&lt;/p&gt; &lt;h2&gt;Sanitizers&lt;/h2&gt; &lt;p&gt;Clang comes with a couple of &lt;i&gt;sanitizers&lt;/i&gt;, which instrument the compiled program at runtime. Sanitizers are usually used for issues that would otherwise require developers to rerun the program and get information about the problematic behavior, which costs additional time. They are also used for issues that don&amp;#8217;t abort the program but cause problems later on, such as integer overflows or access to uninitialized data.&lt;/p&gt; &lt;p&gt;The most useful and common sanitizers supported in Clang are the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/AddressSanitizer.html"&gt;AddressSanitizer&lt;/a&gt; can be used to detect various memory problems such as null pointer dereferences, use-after-free, and double/invalid free. It can be enabled via &lt;code&gt;-fsanitize=address&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/MemorySanitizer.html"&gt;MemorySanitizer&lt;/a&gt; can be used to detect access to uninitialized memory. It can be enabled via &lt;code&gt;-fsanitize=memory&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/ThreadSanitizer.html"&gt;ThreadSanitizer&lt;/a&gt; detects data races in multithreaded programs. It can be enabled via &lt;code&gt;-fsanitize=thread&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html"&gt;UndefinedBehaviorSanitizer&lt;/a&gt; detects various kinds of undefined behavior. It can be enabled via &lt;code&gt;-fsanitize=undefined&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;GCC supports all these sanitizers except for the memory sanitizer. These are the big sanitizers, but both GCC and Clang support many &lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/UsersManual.html#controlling-code-generation"&gt;more fine-grained&lt;/a&gt; checks, so it might be worth checking their documentation for useful sanitizers and their options.&lt;/p&gt; &lt;p&gt;If the software has a test suite (which it should), and that test suite is run in a continuous integration fashion (which it should be), compiling the test suite with some of the sanitizers mentioned in this section makes a lot of sense and does not increase run time as much as running the programs in Valgrind would.&lt;/p&gt; &lt;p&gt;It is, however, certainly also helpful if developers have one or another sanitizer enabled when working on the software itself on a daily basis, to catch errors with real-world data as soon as possible.&lt;/p&gt; &lt;p&gt;For a more in-depth introduction to sanitizers and a comparison to the super useful Valgrind tool, check out &lt;a target="_blank" rel="nofollow" href="/blog/2021/05/05/memory-error-checking-in-c-and-c-comparing-sanitizers-and-valgrind/"&gt;Jan Kratochvil&amp;#8217;s recent article on the topic&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Clang fuzzer&lt;/h2&gt; &lt;p&gt;A &lt;em&gt;fuzzer&lt;/em&gt; is a tool that generates random input for a library under test. Fuzz testing is useful to find errors and crashes in any sort of file parser. Clang contains &lt;a target="_blank" rel="nofollow" href="https://llvm.org/docs/LibFuzzer.html"&gt;libFuzzer&lt;/a&gt;, which can be used for this sort of testing.&lt;/p&gt; &lt;p&gt;The fuzzer will keep providing new input to the library under test until a bug is found, so in the best case, the run of the fuzzer program continues for an indefinite amount of time. This case of fuzzing cannot be used in an automated fashion, but is still very valuable for developers to use manually.&lt;/p&gt; &lt;p&gt;For an introduction to using Clang&amp;#8217;s fuzzer on RHEL with llvm-toolset, read &lt;a target="_blank" rel="nofollow" href="/blog/2019/03/05/introduction-to-using-libfuzzer-with-llvm-toolset/"&gt;this article&lt;/a&gt; by Tom Stellard.&lt;/p&gt; &lt;h2&gt;Link-time optimized (LTO) builds&lt;/h2&gt; &lt;p&gt;More and more distributions are switching to using link-time optimized (LTO) builds. In these builds, the compiler does not emit native object code, but its intermediate representation (IR). The IR is then handed to the linker, which can apply intermodular optimizations.&lt;/p&gt; &lt;p&gt;LTO also helps identify issues with symbol visibility by removing symbols that are unused and not explicitly marked as externally visible. This can help you avoid accidentally exporting symbols that are not meant for public consumption.&lt;/p&gt; &lt;p&gt;Both GCC and LLVM support LTO builds, as well as a couple of configuration options to fit the needs of different use cases. For more details on these options as well as the inner working of the compilers during LTO builds, consult the &lt;a target="_blank" rel="nofollow" href="https://gcc.gnu.org/onlinedocs/gccint/LTO-Overview.html"&gt;GCC&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://llvm.org/docs/LinkTimeOptimization.html"&gt;LLVM&lt;/a&gt; documentation regarding this topic.&lt;/p&gt; &lt;h2&gt;Control flow integrity in Clang&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://clang.llvm.org/docs/ControlFlowIntegrity.html"&gt;Clang&amp;#8217;s control flow integrity (CFI)&lt;/a&gt; is a special type of sanitizer that requires link-time optimization (LTO) to be used. You can enable it via &lt;code&gt;-fsanitize=cfi&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;CFI allows instrumentation of the compiled program to detect certain forms of undefined behavior and to abort the program in these cases. The CFI sanitizer supports different schemes, and they are usually optimized enough so that they can be enabled even in release builds. Google, for example, is known to do this &lt;a target="_blank" rel="nofollow" href="https://source.android.com/devices/tech/debug/cfi"&gt;on Android&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This is an example of security hardening that is available only on Clang right now.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Different compilers come with their strengths and weaknesses. Testing your project with different compilers will ensure you do not rely on particular compiler-specific behaviors—or even bugs. Many open source projects already have a CI pipeline that leverages more than one compiler, configuration, or platform. That is ideal, and you should try to do this for all of your projects if it makes sense for them. If you can&amp;#8217;t, it makes sense to at least use another compiler once in a while, or try to integrate this practice into your local development workflow.&lt;/p&gt; &lt;p&gt;Using sanitizers in your test suite and static analyzers regularly (or even via a special build in CI) is a great way of finding bugs ahead of time. Again, different tools show different defects in your code. Carefully evaluating them pays off in the long run. Try out other tools and use the one you feel most comfortable with on a daily basis. But always keep other options in mind and automate what you can.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#38;linkname=Use%20multiple%20compilers%20to%20build%20better%20projects" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F07%2Fuse-multiple-compilers-to-build-better-projects%2F&amp;#038;title=Use%20multiple%20compilers%20to%20build%20better%20projects" data-a2a-url="https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/" data-a2a-title="Use multiple compilers to build better projects"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/"&gt;Use multiple compilers to build better projects&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/xXslsKHu7G0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;For a multitude of reasons, developers usually compile the project they are working on with only one compiler. On Red Hat Enterprise Linux 8, the system compiler for C and C++ is GNU Compiler Collection (GCC) 8, and newer versions are available through the GCC toolset. However, there are several reasons why you might also [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/"&gt;Use multiple compilers to build better projects&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">896297</post-id><dc:creator>Timm Baeder</dc:creator><dc:date>2021-05-07T07:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/07/use-multiple-compilers-to-build-better-projects/</feedburner:origLink></entry><entry><title type="html">Kogito Tooling 0.9.1 Released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/MBQsIdkStb4/kogito-tooling-0-9-1-released.html" /><author><name>Eder Ignatowicz</name></author><id>https://blog.kie.org/2021/05/kogito-tooling-0-9-1-released.html</id><updated>2021-05-07T05:00:00Z</updated><content type="html">We have just launched a fresh new Kogito Tooling release! &#x1f389; On the 0.9.1 , we made a lot of improvements and bug fixes. We are also happy to announce the MVP of our DMN Runner and many enhancements on Custom Task support on BPMN. This post will give a quick overview of this release and add some highlights of our release. I hope you enjoy it! CUSTOM TASK SUPPORT ENHANCEMENT ON BPMN We made many improvements regarding custom task support on BPMN, especially related to compatibility with Business Central projects. Stay tuned that soon we will publish a blog post with a deep dive into these enhancements. BPMN EDITOR – READ-ONLY MODE We introduced read-only mode support for our BPMN Editors. This feature is handy when you embed our editors using our . Simple pass ‘readOnly:true’ in our editor startup to activate this mode (it also works for DMN). You can also see this new mode in action in our : AUGMENTING THE DEVELOPER EXPERIENCE WITH DMN RUNNER We’ve been exploring ways to augment the developer experience for the Business Modeler Editors. In the spirit of “release early, release often” and MVPs, we’d like to share an early stage of a running prototype of the DMN Runner so that we can gather more feedback. You can watch the presentation of this prototype in or try it out in our environment. Soon we will publish a post with more details. NEW FEATURES, FIXED ISSUES, AND IMPROVEMENTS We also made some new features, a lot of refactorings and improvements, with highlights to: * – [BPMN] Reuse Data Types across the process * – SceSim runner does not display reason for failure * – [Scesim Editor] Bottom scroll bar getting hide * – [DMN Designer] Multiple DRDs support – The undo/redo are lost when the user changes between diagrams * – Unable to view service tasks in VSCode on windows * – Standalone editors setContent implementation should receive path and content * – [DMN Designer] Error during the save/marshaller of specific diagrams * – [DMN Designer] Decision Service is missing inputData element in model with multiple DRDs FURTHER READING/WATCHING We had some cool talks recently at the KIE youtube channel: * Augmenting the developer experience with DMN Runner, by Eder; * LACE Score Demonstration with DMN, by Rachid; * A chat about Open Source, leadership, and communities with Mark Proctor I would like to also recommend the recent article from . He provides a complete step-by-step tutorial to use Test Scenario Editor to test your DMN assets on VS Code and also, this from Guilherme where he details how the new Feel code completion works under the hood. THANK YOU TO EVERYONE INVOLVED! I would like to thank everyone involved with this release, from the excellent KIE Tooling Engineers to the lifesavers QEs and the UX people that help us look awesome! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/MBQsIdkStb4" height="1" width="1" alt=""/&gt;</content><dc:creator>Eder Ignatowicz</dc:creator><feedburner:origLink>https://blog.kie.org/2021/05/kogito-tooling-0-9-1-released.html</feedburner:origLink></entry><entry><title>Why Windows and Linux line endings don’t line up (and how to fix it)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/pDUESnapAjw/" /><category term=".NET" /><category term="Kubernetes" /><category term="Linux" /><category term="Windows" /><category term="Linux line endings" /><category term="Windows in containers" /><category term="Windows line endings" /><author><name>Don Schenck</name></author><id>https://developers.redhat.com/blog/?p=894667</id><updated>2021-05-06T07:00:54Z</updated><published>2021-05-06T07:00:54Z</published><content type="html">&lt;p&gt;I recently wrote a few automated database-populating scripts. Specifically, I am running Microsoft SQL Server in a container in a Kubernetes cluster—okay, it&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, but it&amp;#8217;s still &lt;a target="_blank" rel="nofollow" href="/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. It was all fun and games until I started mixing &lt;a target="_blank" rel="nofollow" href="/blog/category/windows/"&gt;Windows&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="/topics/linux"&gt;Linux&lt;/a&gt;; I was developing on my Windows machine, but obviously the container is running Linux. That&amp;#8217;s when I got the gem of an error shown in Figure 1. Well, not so much an error as errant output.&lt;/p&gt; &lt;div id="attachment_894697" style="width: 386px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/04/crlf_errant_output.png"&gt;&lt;img aria-describedby="caption-attachment-894697" class="wp-image-894697 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/crlf_errant_output.png" alt="Weird line endings in SQL statement output." width="376" height="258" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/crlf_errant_output.png 376w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/crlf_errant_output-300x206.png 300w" sizes="(max-width: 376px) 100vw, 376px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-894697" class="wp-caption-text"&gt;Figure 1: Errant output from an SQL statement.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;span id="more-894667"&gt;&lt;/span&gt;What in the world? Here&amp;#8217;s the CSV data I used to populate the table:&lt;/p&gt; &lt;pre&gt;1,Active 2,Inactive 3,Ordered 4,Billed 5,Shipped &lt;/pre&gt; &lt;p&gt;Here&amp;#8217;s the T-SQL code I used for the same purpose:&lt;/p&gt; &lt;pre&gt;BULK INSERT dbo.StatusCodes FROM '/tmp/StatusCodes.csv' WITH (FORMAT='CSV',FIELDTERMINATOR=',',KEEPIDENTITY); GO SELECT * FROM dbo.StatusCodes; GO &lt;/pre&gt; &lt;p&gt;What is going on here?&lt;/p&gt; &lt;h2&gt;TL;DR: Line endings&lt;/h2&gt; &lt;p&gt;It&amp;#8217;s the line endings. They are the issue.&lt;/p&gt; &lt;p&gt;Specifically, Windows and Linux handle line endings differently. To understand why, we need to go back a ways in history.&lt;/p&gt; &lt;h2&gt;ASDFJKL&lt;/h2&gt; &lt;p&gt;Ever use a manual typewriter? Okay, okay &amp;#8230; enough of the &amp;#8220;That&amp;#8217;s old!&amp;#8221; jokes. Figure 2 illustrates.&lt;/p&gt; &lt;div id="attachment_894797" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a target="_blank" rel="nofollow" href="https://pixabay.com/photos/typewriter-isolated-nostalgic-old-1138293/"&gt;&lt;img aria-describedby="caption-attachment-894797" class="wp-image-894797" src="https://developers.redhat.com/blog/wp-content/uploads/2021/04/typewriter-1138293_640-300x218.png" alt="A photograph of a manual typewriter. Image by Gerhard G. on Pixabay." width="500" height="364" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/04/typewriter-1138293_640-300x218.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/04/typewriter-1138293_640.png 640w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-894797" class="wp-caption-text"&gt;Figure 2: What a manual typewriter looks like.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The typewriter mechanism that holds the rubber cylinder is called the &lt;em&gt;carriage&lt;/em&gt; because it carries the paper. (That rubber cylinder is technically known as a &lt;em&gt;platen&lt;/em&gt;, but stay with me as I employ poetic license and use &amp;#8220;carriage.&amp;#8221;)&lt;/p&gt; &lt;p&gt;As you type, the carriage moves to the left. When you reach the edge of the paper, you use the big lever on the far left to return the carriage to the starting position; that is, you perform a &lt;em&gt;carriage return&lt;/em&gt;. In addition, as the lever moves, it advances the paper up one line, which is known as a &lt;em&gt;line feed&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;When you do both movements, you get &amp;#8220;carriage return plus line feed,&amp;#8221; sometimes abbreviated to CRLF or CR/LF. You &lt;em&gt;can&lt;/em&gt; move the carriage without feeding one line, and you &lt;em&gt;can&lt;/em&gt; advance one line without moving the carriage. They are two distinct and separate actions, but anyone who has mastered the manual typewriter knows that they are typically done in one, swift, soulful, and athletic motion, akin to desktop gymnastics of the highest order. (Please excuse more poetic license as I romanticize about typing.)&lt;/p&gt; &lt;h2&gt;Teletype&lt;/h2&gt; &lt;p&gt;Meanwhile, over in the world of automation, the Teletype machine became very popular. This allowed the transmission of text around the world, across telephone lines. But long distance calls were expensive, so minimizing the time and data sent was paramount. So, it was decided that one and only one character would be used for a carriage return and line feed, the so-called &lt;em&gt;new line character&lt;/em&gt;. You see it as &amp;#8220;&lt;code&gt;\n&lt;/code&gt;&amp;#8221; in code. You paid for every byte, back then, so cutting costs was important.&lt;/p&gt; &lt;p&gt;We&amp;#8217;re talking about 300 baud modems here, folks. Just think about that; 300 bits per second; &lt;em&gt;three hundred&lt;/em&gt;. Now, we want gigabits everywhere.&lt;/p&gt; &lt;h2&gt;Back to line endings&lt;/h2&gt; &lt;p&gt;The reasons don&amp;#8217;t matter: Windows chose the CR/LF model, while Linux uses the &lt;code&gt;\n&lt;/code&gt; model. So, when you create a file on one system and use it on the other, hilarity ensues. Or, in this case, two hours of debugging ending in madness and me contemplating a new career in woodworking.&lt;/p&gt; &lt;h2&gt;Quick fix for Linux and Windows line endings&lt;/h2&gt; &lt;p&gt;The quick fix for those incompatible line endings was very simple: I altered my T-SQL to include the ROWTERMINATOR specification, like this:&lt;/p&gt; &lt;pre&gt;BULK INSERT dbo.StatusCodes FROM '/tmp/StatusCodes.csv' WITH (FORMAT='CSV',FIELDTERMINATOR=',',ROWTERMINATOR = '\r\n',KEEPIDENTITY); GO SELECT * FROM dbo.StatusCodes; GO &lt;/pre&gt; &lt;p&gt;That works when uploading my CSV from my Windows machine. When uploading from my Linux machine, I use the following, where the ROWTERMINATOR is the simple new line character:&lt;/p&gt; &lt;pre&gt;BULK INSERT dbo.StatusCodes FROM '/tmp/StatusCodes.csv' WITH (FORMAT='CSV',FIELDTERMINATOR=',',ROWTERMINATOR = '\n',KEEPIDENTITY); GO SELECT * FROM dbo.StatusCodes; GO &lt;/pre&gt; &lt;p&gt;Simple, but unless you know about it, you either get weird results or some seemingly unrelated error messages. So, be advised. For example, if I try to use the Windows-specific command (where ROWTERMINATOR is &amp;#8220;&lt;code&gt;\r\n&lt;/code&gt;&amp;#8220;) in my Linux environment, I get the following error:&lt;/p&gt; &lt;pre&gt;Msg 4879, Level 16, State 1, Server mssql-1-h2c96, Line 2 Bulk load failed due to invalid column value in CSV data file /tmp/StatusCodes.csv in row 1, column 2. Msg 7399, Level 16, State 1, Server mssql-1-h2c96, Line 2 The OLE DB provider "BULK" for linked server "(null)" reported an error. The provider did not give any information about the error. Msg 7330, Level 16, State 2, Server mssql-1-h2c96, Line 2 Cannot fetch a row from OLE DB provider "BULK" for linked server "(null)". Id statusCodeDescription ----------- --------------------- &lt;/pre&gt; &lt;h2&gt;What does it all mean?&lt;/h2&gt; &lt;p&gt;The upshot is this: You might see some hiccups and weird behavior when you use a file in both Windows and Linux. Just be aware of it and you&amp;#8217;ll be fine.&lt;/p&gt; &lt;p&gt;Visit my GitHub repository &lt;a target="_blank" rel="nofollow" href="https://github.com/donschenck/netcandystore"&gt;NetCandyStore&lt;/a&gt; for all of the code referenced in this article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#38;linkname=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fwhy-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it%2F&amp;#038;title=Why%20Windows%20and%20Linux%20line%20endings%20don%E2%80%99t%20line%20up%20%28and%20how%20to%20fix%20it%29" data-a2a-url="https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/" data-a2a-title="Why Windows and Linux line endings don’t line up (and how to fix it)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/"&gt;Why Windows and Linux line endings don&amp;#8217;t line up (and how to fix it)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/pDUESnapAjw" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;I recently wrote a few automated database-populating scripts. Specifically, I am running Microsoft SQL Server in a container in a Kubernetes cluster—okay, it&amp;#8217;s Red Hat OpenShift, but it&amp;#8217;s still Kubernetes. It was all fun and games until I started mixing Windows and Linux; I was developing on my Windows machine, but obviously the container is [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/"&gt;Why Windows and Linux line endings don&amp;#8217;t line up (and how to fix it)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">894667</post-id><dc:creator>Don Schenck</dc:creator><dc:date>2021-05-06T07:00:54Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/06/why-windows-and-linux-line-endings-dont-line-up-and-how-to-fix-it/</feedburner:origLink></entry><entry><title>Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ikKoWxcNCcw/" /><category term="CI/CD" /><category term="Linux" /><category term="Open source" /><category term="Performance" /><category term="buildbot" /><category term="Linux kernel" /><category term="systemtap" /><category term="test automation" /><author><name>Serhei Makarov</name></author><id>https://developers.redhat.com/blog/?p=843537</id><updated>2021-05-06T07:00:12Z</updated><published>2021-05-06T07:00:12Z</published><content type="html">&lt;p&gt;Over the past year, I have been implementing an automated infrastructure to test the &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/systemtap/"&gt;SystemTap&lt;/a&gt; project and to collect and analyze the test results. SystemTap is a scripting language for creating instrumentation to observe a live running &lt;a target="_blank" rel="nofollow" href="/topics/linux"&gt;Linux&lt;/a&gt; kernel and user-space applications. The SystemTap language translator produces Linux kernel modules. These modules depend on internal details of the Linux kernel that vary significantly between different versions of Linux.&lt;/p&gt; &lt;p&gt;The process of developing the SystemTap project and maintaining it for a wide range of Linux kernel versions requires a strategy to detect and fix unexpected bugs. Bugs can arise not only from changes in the SystemTap project, but also from changes in newer versions of the Linux kernel.&lt;/p&gt; &lt;p&gt;In order to verify the safety and correct behavior of SystemTap, the SystemTap project includes a test suite based on the &lt;a target="_blank" rel="nofollow" href="https://www.gnu.org/software/dejagnu/"&gt;DejaGnu&lt;/a&gt; framework. However, up to now there was no system for running this test suite each time someone made a commit to the SystemTap Git repository. An infrastructure that automatically runs the test suite and reports new test failures would be very helpful for detecting and fixing bugs as early as possible during the SystemTap development process.&lt;/p&gt; &lt;p&gt;This article is the first of two articles summarizing the tools that I developed and used to automate the process of testing SystemTap and detecting test failures. For the purpose of these articles, I consider the testing process to consist of seven steps. I describe the implementation for each of these steps and finish by summarizing my key design ideas and outlining potential future improvements.&lt;/p&gt; &lt;p&gt;The ideas presented in these articles could be useful for other &lt;a target="_blank" rel="nofollow" href="/topics/open-source"&gt;open source&lt;/a&gt; projects with complex testing requirements.&lt;/p&gt; &lt;h2&gt;Seven steps for successful testing&lt;/h2&gt; &lt;p&gt;When developing an infrastructure for testing and test-result analysis, I found that commonly used &lt;a target="_blank" rel="nofollow" href="/topics/ci-cd"&gt;continuous integration&lt;/a&gt; (CI) systems are insufficient for testing SystemTap. Most CI systems assume a problem formulation in which a commit to a project should be accepted or rejected depending on whether testing the resulting version produces a &amp;#8220;pass&amp;#8221; or &amp;#8220;fail&amp;#8221; result on a specified set of test cases. This formulation is not sufficient for testing SystemTap.&lt;/p&gt; &lt;p&gt;An infrastructure for testing SystemTap must take several difficult concerns into account. The &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=systemtap.git;a=tree;f=testsuite"&gt;SystemTap test suite&lt;/a&gt; contains a large number of test cases that are nondeterministic or environment-sensitive. Some of these test cases are important, whereas others are included to monitor the availability of optional SystemTap functionality across different systems. It would be difficult to decide on a single &amp;#8220;pass&amp;#8221; or &amp;#8220;fail&amp;#8221; verdict for the entire set of test results.&lt;/p&gt; &lt;p&gt;A set of test results could contain a number of important test failures that indicate new bugs that should be fixed, intermixed with unimportant test failures that occur on a regular basis. Test failures could also arise because of changes in the test environment, particularly changes to kernel internals after a kernel update. Because these test failures are not caused by changes in SystemTap code, they cannot be prevented by rejecting or reverting a SystemTap commit. The only solution is to detect the test failure and to fix or extend SystemTap to support the changed environment.&lt;/p&gt; &lt;p&gt;To design an infrastructure for testing SystemTap, I analyzed the testing process from the top level and defined a testing scheme consisting of seven steps. Some of these steps could be automated with basic shell scripts and existing tools. Other steps required me to develop entirely new software for test result analysis.&lt;/p&gt; &lt;p&gt;The first three steps relate to testing the project and collecting test results. I determined that these steps could be handled with shell scripts and existing software—namely the &lt;a target="_blank" rel="nofollow" href="https://libvirt.org"&gt;libvirt&lt;/a&gt; virtual machine (VM) provisioning system and the &lt;a target="_blank" rel="nofollow" href="https://buildbot.net"&gt;Buildbot&lt;/a&gt; test-automation toolkit. These steps are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Step 1: Provisioning test machines and VMs.&lt;/li&gt; &lt;li&gt;Step 2: Installing the SystemTap project and running the test suite.&lt;/li&gt; &lt;li&gt;Step 3: Sending test results to a central location.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The remaining four steps pertain to storing the collected test results and to analyzing them to discover and report new test failures. To handle these steps, I developed a test result storage and analysis toolkit called &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=summary"&gt;Bunsen&lt;/a&gt;. These steps are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Step 4: Receiving and storing test results in a compact format.&lt;/li&gt; &lt;li&gt;Step 5: Querying the test results. When we obtain a new set of test results, we want to view those results and compare them with test results for earlier versions.&lt;/li&gt; &lt;li&gt;Step 6: Analyzing the test results. To filter out newly occurring test failures from previously occurring failures, we need to use information from the entire history of test results.&lt;/li&gt; &lt;li&gt;Step 7: Reporting the analysis in a readable format.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In terms of equipment, my testing infrastructure consists of a set of test machines and a server that acts as a &lt;em&gt;virtual machine host&lt;/em&gt; and &lt;em&gt;test result storage server&lt;/em&gt;. Currently, this infrastructure operates internally at Red Hat. Figure 1 summarizes the components of the testing infrastructure and how they interact.&lt;/p&gt; &lt;div id="attachment_843677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/12/bunsen-2020-12-workflow.png"&gt;&lt;img aria-describedby="caption-attachment-843677" class="wp-image-843677" src="https://developers.redhat.com/blog/wp-content/uploads/2020/12/bunsen-2020-12-workflow.png" alt="The SystemTap testing infrastructure contains many components, whose interactions are shown in this figure." width="640" height="686" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-843677" class="wp-caption-text"&gt;Figure 1: Components of the SystemTap testing infrastructure and their interactions.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This article explains in detail the first three steps of the testing process and how these steps are implemented by my testing infrastructure. I&amp;#8217;ll cover the remaining four steps in the next article.&lt;/p&gt; &lt;h2&gt;Step 1: Provisioning test machines and VMs&lt;/h2&gt; &lt;p&gt;The purpose of this step is to maintain a set of test machines with a range of hardware architectures and kernel versions. SystemTap must be tested on a wide variety of system configurations because of its complex dependencies on the Linux kernel’s internals and on the hardware architecture.&lt;/p&gt; &lt;p&gt;I found that maintaining the required set of test machines manually would entail a significant and recurring maintenance burden. My primary source of test machines was a virtual-machine server running the &lt;a target="_blank" rel="nofollow" href="https://www.linux-kvm.org/page/Main_Page"&gt;KVM&lt;/a&gt; hypervisor with the &lt;a target="_blank" rel="nofollow" href="https://libvirt.org"&gt;libvirt&lt;/a&gt; virtual-machine management tools. I was also able to provision test machines on a temporary basis from pools of hardware resources managed by systems such as &lt;a target="_blank" rel="nofollow" href="https://www.openstack.org"&gt;OpenStack&lt;/a&gt; or &lt;a target="_blank" rel="nofollow" href="https://beaker-project.org"&gt;Beaker&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I needed to initialize each test machine with a Linux distribution and configure it to run the SystemTap test suite. Doing so manually would entail frequent repetitive work.&lt;/p&gt; &lt;p&gt;As I developed my testing infrastructure, it became clear that the best way to avoid repetitive manual maintenance would be to make it as simple as possible to provision new test machines.&lt;/p&gt; &lt;p&gt;Therefore, I developed &lt;code&gt;buildbot-create-vm.sh&lt;/code&gt;, a shell script that invokes the &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/configuring_and_managing_virtualization/index#creating-virtual-machines-using-the-command-line-interface_assembly_creating-virtual-machines"&gt;virt-install&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://libguestfs.org/virt-customize.1.html"&gt;virt-customize&lt;/a&gt; commands to create and configure a virtual machine for testing SystemTap. &lt;code&gt;virt-install&lt;/code&gt; and &lt;code&gt;virt-customize&lt;/code&gt; are command-line tools, included in both the &lt;a target="_blank" rel="nofollow" href="https://libvirt.org"&gt;libvirt&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://libguestfs.org"&gt;libguestfs&lt;/a&gt; projects, that can automatically create a virtual machine and modify the contents of its filesystem. The example commands in this section are based on &lt;code&gt;buildbot-create-vm.sh&lt;/code&gt; and illustrate how the &lt;code&gt;virt-install&lt;/code&gt; and &lt;code&gt;virt-customize&lt;/code&gt; commands can be used.&lt;/p&gt; &lt;p&gt;The following command invokes &lt;code&gt;virt-install&lt;/code&gt; to create a new virtual machine:&lt;/p&gt; &lt;pre&gt;NAME=buildbot_example \ LOCATION=http://download.fedoraproject.org/pub/fedora/linux/development/33/Server/x86_64/os/ \ virt-install --name=$NAME --os-variant=fedora32 \ --vcpus 2 --memory 4096 \ --disk pool=default,size=25 \ --autostart --watchdog default \ --location=$LOCATION \ --network bridge=br0 \ --graphics=none --extra-args console=ttyS0 \ --unattended admin-password-file=$PASSWORD \ --noreboot &lt;/pre&gt; &lt;p&gt;This command assumes that a libvirt storage pool named &lt;code&gt;default&lt;/code&gt; is available for creating a new virtual disk. The &lt;code&gt;LOCATION&lt;/code&gt; variable specifies the URL of a mirror for network installation of Fedora Linux.&lt;/p&gt; &lt;p&gt;And the following command invokes &lt;code&gt;virt-customize&lt;/code&gt; to initialize the newly created VM with additional configuration:&lt;/p&gt; &lt;pre&gt;NAME=buildbot_example \ REPO_FILE=example_custom.repo \ BUILDBOT_INSTALL_SH=/path/to/buildbot-install.sh \ SSH_PUBLIC_KEY=$(cat id_rsa_casual.pub) \ virt-customize -d $NAME \ --hostname "$NAME.local" \ --copy-in $REPO_FILE:/etc/yum.repos.d \ --copy-in $BUILDBOT_INSTALL_SH:/root \ --append-line $'/etc/crontab:@reboot\troot\tbash -c "chmod +x /root/buildbot-install.sh; /root/buildbot-install.sh 2&amp;#62;&amp;#38;1 &amp;#62;/root/crontab-firstboot.log"' \ --edit $'/etc/ssh/sshd_config:s/^# ?PermitRootLogin .*/PermitRootLogin yes/' \ --mkdir /root/.ssh \ --append-line "/root/.ssh/authorized_keys:$SSH_PUBLIC_KEY" \ --chmod $'0600:/root/.ssh/authorized_keys' &lt;/pre&gt; &lt;p&gt;This command creates a crontab file that will run the script &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt; when the VM starts running. As described in the next section, this script installs a SystemTap development environment and configures it for automated testing.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;REPO_FILE&lt;/code&gt; variable contains the name of a custom DNF package repository, while &lt;code&gt;BUILDBOT_INSTALL_SH&lt;/code&gt; specifies the location of the &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt; script described in the next section. In addition, the &lt;code&gt;SSH_PUBLIC_KEY&lt;/code&gt; variable is initialized with an SSH public key that will be used for logging into the test machine remotely.&lt;/p&gt; &lt;h2&gt;Step 2: Installing the SystemTap project and running the test suite&lt;/h2&gt; &lt;p&gt;The purpose of this step is to set up the newly provisioned test machines with a SystemTap development environment and to configure the machines to launch the SystemTap test suite automatically whenever a commit is made to the main SystemTap Git repository on sourceware.org.&lt;/p&gt; &lt;p&gt;For setting up a SystemTap development environment, I developed several shell scripts: &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt; and &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-install.sh;hb=HEAD"&gt;stap-install.sh&lt;/a&gt; to install the developer tools required to build SystemTap, and &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-test.sh;hb=HEAD"&gt;stap-test.sh&lt;/a&gt; to download, compile, and test the SystemTap project from source. These scripts assume that the test machine will be dedicated exclusively for testing SystemTap.&lt;/p&gt; &lt;p&gt;For long-term testing of SystemTap, it is safest to use a dedicated test machine, since the full SystemTap test suite includes a number of &amp;#8220;stress tests&amp;#8221; that deliberately weaken or disable some of SystemTap’s safety mechanisms. On rare occasions, a failure result for one of these test cases can produce a kernel panic or hard lockup.&lt;/p&gt; &lt;p&gt;Before launching the SystemTap test suite, &lt;code&gt;stap-test.sh&lt;/code&gt; performs a number of helpful configuration steps not handled by the SystemTap project’s &lt;code&gt;make installcheck&lt;/code&gt; test suite command, including the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;stap-test.sh&lt;/code&gt; ensures that a &lt;code&gt;kernel-devel&lt;/code&gt; package is installed with a version exactly matching the currently running kernel. A &lt;code&gt;kernel-devel&lt;/code&gt; package is required to allow SystemTap to compile kernel modules that can carry out system-wide observations. Because some distributions&amp;#8217; package repositories provide only the latest version of each package, the &lt;code&gt;kernel-devel&lt;/code&gt; package for the currently running kernel might no longer be available. In that case, &lt;code&gt;stap-test.sh&lt;/code&gt; updates the kernel to match the available version of the &lt;code&gt;kernel-devel&lt;/code&gt; package and reboots the test machine.&lt;/li&gt; &lt;li&gt;&lt;code&gt;stap-test.sh&lt;/code&gt; checks whether the &lt;a target="_blank" rel="nofollow" href="https://debuginfod.elfutils.org"&gt;debuginfod.elfutils.org&lt;/a&gt; server provides debuginfo for the Linux distribution and currently running kernel on the test machine, and accordingly enables or disables SystemTap&amp;#8217;s support for retrieving kernel debuginfo via &lt;code&gt;debuginfod&lt;/code&gt;. When &lt;code&gt;debuginfod&lt;/code&gt; support is disabled, &lt;code&gt;stap-test.sh&lt;/code&gt; runs the &lt;code&gt;stap-prep&lt;/code&gt; script provided by SystemTap to attempt to install a debuginfo package for the current kernel. More information about SystemTap&amp;#8217;s support for &lt;code&gt;debuginfod&lt;/code&gt; can be found in the article &lt;a target="_blank" rel="nofollow" href="/blog/2019/10/14/introducing-debuginfod-the-elfutils-debuginfo-server/"&gt;Introducing debuginfod, the elfutils debuginfo server&lt;/a&gt; by Aaron Merey.&lt;/li&gt; &lt;li&gt;&lt;code&gt;stap-test.sh&lt;/code&gt; runs the &lt;a target="_blank" rel="nofollow" href="https://man7.org/linux/man-pages/man1/dmesg.1.html"&gt;dmesg&lt;/a&gt; command to capture the Linux kernel ring buffer output into an additional file included with the final test results. In my experience, this output is important to capture because it may contain additional information about kernel warnings or crashes triggered by SystemTap test cases.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I’ve &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=tree;f=scripts-guest/systemtap;hb=HEAD"&gt;published&lt;/a&gt; the &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-install.sh;hb=HEAD"&gt;stap-install.sh&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-test.sh;hb=HEAD"&gt;stap-test.sh&lt;/a&gt; scripts for anyone who is interested in quickly setting up a SystemTap environment and running the test suite.&lt;/p&gt; &lt;p&gt;To launch the SystemTap test suite automatically across the full set of test machines, I use an instance of the &lt;a target="_blank" rel="nofollow" href="https://buildbot.net"&gt;Buildbot&lt;/a&gt; system. The Buildbot system runs on the test result server and accepts connections from Buildbot workers running on the test machines.&lt;/p&gt; &lt;p&gt;Whenever a new test machine is provisioned, a Buildbot worker is automatically installed and configured on the machine by &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt;. After connecting to the Buildbot system, the Buildbot worker waits for testing requests.&lt;/p&gt; &lt;p&gt;The Buildbot service regularly checks the SystemTap Git repository on sourceware.org for new commits. When a commit is made to the SystemTap Git repository, the Buildbot service sends a request to the Buildbot worker on each of the test machines. The Buildbot workers then invoke the &lt;code&gt;stap-test.sh&lt;/code&gt; script.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;buildbot-install-stap.sh&lt;/code&gt; script can also be invoked manually on a test machine that was provisioned either by hand or from a pool of test machines managed by a system such as OpenStack or Beaker. This manual invocation option has proven useful for quickly setting up test machines on a variety of architectures besides x86.&lt;/p&gt; &lt;p&gt;The Buildbot system includes some functionality for collecting and displaying test results, but I decided not to rely on it. Buildbot assumes a testing process that is modeled as a series of stages, and each of these stages is expected to have a simple &amp;#8220;pass&amp;#8221; or &amp;#8220;fail&amp;#8221; outcome. As mentioned earlier, this model is appropriate for a continuous integration system, but is too simple for a project such as SystemTap whose test suite includes many nondeterministic or environment-dependent test cases.&lt;/p&gt; &lt;h2&gt;Step 3: Sending test results to a central location&lt;/h2&gt; &lt;p&gt;The purpose of this step is to collect in one location the SystemTap test results produced by the various test machines.&lt;/p&gt; &lt;p&gt;After running the SystemTap test suite, the &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/git/?p=bunsen.git;a=blob;f=scripts-guest/systemtap/stap-test.sh;hb=HEAD"&gt;stap-test.sh&lt;/a&gt; script packages the test results in a tar archive and sends them to the test result server. The test results produced by SystemTap’s &lt;a target="_blank" rel="nofollow" href="https://www.gnu.org/software/dejagnu/"&gt;DejaGnu&lt;/a&gt; test suite consist of a &lt;code&gt;systemtap.log&lt;/code&gt; and a &lt;code&gt;systemtap.sum&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;systemtap.log&lt;/code&gt; file contains the detailed output of every test case in the test suite, while the &lt;code&gt;systemtap.sum&lt;/code&gt; file contains a condensed summary of the results for each test case.&lt;/p&gt; &lt;p&gt;In addition to the DejaGnu output, the &lt;code&gt;stap-test.sh&lt;/code&gt; script also sends a file of system diagnostics collected by the &lt;a target="_blank" rel="nofollow" href="https://man7.org/linux/man-pages/man1/stap-report.1.html"&gt;stap-report&lt;/a&gt; command, as well as a file named &lt;code&gt;systemtap.dmesg&lt;/code&gt; containing kernel ring buffer data captured during the test suite execution.&lt;/p&gt; &lt;p&gt;The following command from &lt;code&gt;stap-test.sh&lt;/code&gt; packages and sends the test result log files to the test result server:&lt;/p&gt; &lt;pre&gt;tar cvzf - $LOGPATH/systemtap.log* $LOGPATH/systemtap.sum* $LOGPATH/systemtap.dmesg* $LOGPATH/stap-report.* | curl -X POST -F 'project=systemtap' -F 'tar=@-' $BUNSEN_URL/bunsen-upload.py &lt;/pre&gt; &lt;p&gt;Here, the variable &lt;code&gt;LOGPATH&lt;/code&gt; specifies the location of the test result log files and the variable &lt;code&gt;BUNSEN_URL&lt;/code&gt; specifies the location of the test result server.&lt;/p&gt; &lt;p&gt;On the test result server, test results are accepted by a CGI script that adds the log files to a test-result repository managed by the Bunsen toolkit, as described in the next article in the series.&lt;/p&gt; &lt;h2&gt;To be continued &amp;#8230;&lt;/h2&gt; &lt;p&gt;This article described the automated testing infrastructure I developed for the SystemTap project. The next article will describe Bunsen, the toolkit I developed for test result storage and analysis.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#38;linkname=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F05%2F06%2Fautomating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot%2F&amp;#038;title=Automating%20the%20testing%20process%20for%20SystemTap%2C%20Part%201%3A%20Test%20automation%20with%20libvirt%20and%20Buildbot" data-a2a-url="https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/" data-a2a-title="Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/"&gt;Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ikKoWxcNCcw" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Over the past year, I have been implementing an automated infrastructure to test the SystemTap project and to collect and analyze the test results. SystemTap is a scripting language for creating instrumentation to observe a live running Linux kernel and user-space applications. The SystemTap language translator produces Linux kernel modules. These modules depend on internal [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/"&gt;Automating the testing process for SystemTap, Part 1: Test automation with libvirt and Buildbot&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">843537</post-id><dc:creator>Serhei Makarov</dc:creator><dc:date>2021-05-06T07:00:12Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/05/06/automating-the-testing-process-for-systemtap-part-1-test-automation-with-libvirt-and-buildbot/</feedburner:origLink></entry></feed>
